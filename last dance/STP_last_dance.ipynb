{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10973556,"sourceType":"datasetVersion","datasetId":6700028},{"sourceId":316767,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":267330,"modelId":288386},{"sourceId":280452,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":240279,"modelId":261927}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install jiwer\n!pip install ultralytics\n!pip install fuzzywuzzy\nimport os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torchvision.transforms as transforms\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, TrOCRProcessor, VisionEncoderDecoderModel\nfrom google.colab import drive\nimport gdown\nfrom ultralytics import YOLO\nimport re\nfrom rapidfuzz import fuzz, process\nimport matplotlib.pyplot as plt\nfrom google.colab.patches import cv2_imshow\nfrom PIL import Image\nimport torch\n#yoloV8 wieghts\nmodel = YOLO(\"/kaggle/input/yolo-weights-word-detection/pytorch/default/1/worddetection.pt\")  # Path to your downloaded weights\n\n\nmedicine_list=['Acetazolamide', 'Acetylcysteine', 'Albendazole', 'Amantadine', 'Amoxicillin', 'Artificial Tears', 'Atropine', 'Azithromycin', 'Bimatoprost', 'Botox', 'Brimonidine', 'Calcium Carbonate', 'Carbachol', 'Carbamazepine', 'Carbocisteine', 'Cefdinir', 'Cefixime', 'Cefuroxime', 'Cetirizine', 'Chloramphenicol', 'Chlorhexidine', 'Ciprofloxacin', 'Clindamycin', 'Collagen', 'Cyclosporine', 'Dexamethasone', 'Dextromethorphan', 'Diclofenac', 'Domperidone', 'Donepezil', 'Dorzolamide', 'Doxycycline', 'Erythromycin', 'Fluorometholone', 'Gabapentin', 'Gatifloxacin', 'Glycolic Acid', 'Guaifenesin', 'Hyaluronic Acid', 'Hydrocortisone', 'Hydroquinone', 'Hydroxyzine', 'Ibuprofen', 'Iron Supplements', 'Ketorolac', 'Lactic Acid', 'Latanoprost', 'Levetiracetam', 'Levofloxacin', 'Lidocaine', 'Lifitegrast', 'Loratadine', 'Mannitol', 'Mebendazole', 'Memantine', 'Metoclopramide', 'Metronidazole', 'Montelukast', 'Moxifloxacin', 'Multivitamins', 'Mupirocin', 'Natamycin', 'Nepafenac', 'Niacinamide', 'Nystatin', 'Ofloxacin', 'Omeprazole', 'Ondansetron', 'Oral Rehydration Salts', 'Paracetamol', 'Peptides', 'Pilocarpine', 'Pramipexole', 'Prednisolone', 'Prednisolone Acetate', 'Prednisolone Drops', 'Pregabalin', 'Probiotics', 'Ranitidine', 'Retinol', 'Rivastigmine', 'Ropinirole', 'Salbutamol', 'Salicylic Acid', 'Sodium Hyaluronate', 'Timolol', 'Tobramycin', 'Topiramate', 'Travoprost', 'Tretinoin', 'Tropicamide', 'Valproate', 'Vitamin C Serum', 'Vitamin D', 'Voriconazole', 'Zinc Sulfate', 'أتروبين', 'أزيثروميسين', 'أسيتات البريدنيزولون', 'أسيتازولاميد', 'أسيتيل سيستين', 'ألبيندازول', 'أمانتادين', 'أملاح الإماهة الفموية', 'أموكسيسيلين', 'أوفلوكساسين', 'أوميبرازول', 'أوندانسيترون', 'إريثرومايسين', 'إيبوبروفين', 'الببتيدات', 'البروبيوتيك', 'البوتوكس', 'الفيتامينات المتعددة', 'باراسيتامول', 'براميبيكسول', 'بريجابالين', 'بريدنيزولون', 'بريمونيدين', 'بيلوكاربين', 'بيماتوبروست', 'ترافوبروست', 'تروبيكاميد', 'تريتينوين', 'توبراميسين', 'توبيراميت', 'تيمولول', 'جابابنتين', 'جاتيفلوكساسين', 'حمض الجليكوليك', 'حمض الساليسيليك', 'حمض اللاكتيك', 'حمض الهيالورونيك', 'دموع صناعية', 'دورزولاميد', 'دوكسيسيكلين', 'دومبيريدون', 'دونيبيزيل', 'ديكساميثازون', 'ديكستروميثورفان', 'ديكلوفيناك', 'رانيتيدين', 'روبينيرول', 'ريتينول', 'ريفاستجمين', 'سالبيوتامول', 'سيبروفلوكساسين', 'سيتريزين', 'سيفدينير', 'سيفوريوكسيم', 'سيفيكسيم', 'سيكلوسبورين', 'غوايفينيسين', 'فالبروات', 'فلوروميثولون', 'فوريكونازول', 'فيتامين د', 'قطرات بريدنيزولون', 'كارباشول', 'كاربامازيبين', 'كاربوسيستين', 'كبريتات الزنك', 'كربونات الكالسيوم', 'كلورامفينيكول', 'كلورهيكسيدين', 'كليندامايسين', 'كولاجين', 'كيتورولاك', 'لاتانوبروست', 'لوراتادين', 'ليدوكايين', 'ليفوفلوكساسين', 'ليفيتيجراست', 'ليفيتيراسيتام', 'مانيتول', 'مصل فيتامين سي', 'مكملات الحديد', 'موبيروسين', 'موكسيفلوكساسين', 'مونتيلوكاست', 'ميبيندازول', 'ميترونيدازول', 'ميتوكلوبراميد', 'ميمانتين', 'ناتاميسين', 'نياسيناميد', 'نيبافيناك', 'نيستاتين', 'هيالورونات الصوديوم', 'هيدروكسيزين', 'هيدروكورتيزون', 'هيدروكينون']\nArabicWords=['٨', 'دقائق', '١٢', 'قبل', 'الأكل', 'أسبوع', '٥', 'النوم', 'ليلا', 'ساعات', 'لأول', 'يوم', 'مرة', 'اليقظة', '٤', 'كل', '٧', 'دقيقة', 'أثناء', '٣', '٦', 'يومين', 'الفطار', 'مرتين', '١٤', 'واحدة', 'أيام', 'الغداء', 'اللزوم', 'ساعة', 'لمدة', 'يوميا', 'بعد', 'فقط', 'صباحا', 'عند', '١٥' ,'أتروبين', 'أزيثروميسين', 'أسيتات البريدنيزولون', 'أسيتازولاميد', 'أسيتيل سيستين', 'ألبيندازول', 'أمانتادين', 'أملاح الإماهة الفموية', 'أموكسيسيلين', 'أوفلوكساسين', 'أوميبرازول', 'أوندانسيترون', 'إريثرومايسين', 'إيبوبروفين', 'الببتيدات', 'البروبيوتيك', 'البوتوكس', 'الفيتامينات المتعددة', 'باراسيتامول', 'براميبيكسول', 'بريجابالين', 'بريدنيزولون', 'بريمونيدين', 'بيلوكاربين', 'بيماتوبروست', 'ترافوبروست', 'تروبيكاميد', 'تريتينوين', 'توبراميسين', 'توبيراميت', 'تيمولول', 'جابابنتين', 'جاتيفلوكساسين', 'حمض الجليكوليك', 'حمض الساليسيليك', 'حمض اللاكتيك', 'حمض الهيالورونيك', 'دموع صناعية', 'دورزولاميد', 'دوكسيسيكلين', 'دومبيريدون', 'دونيبيزيل', 'ديكساميثازون', 'ديكستروميثورفان', 'ديكلوفيناك', 'رانيتيدين', 'روبينيرول', 'ريتينول', 'ريفاستجمين', 'سالبيوتامول', 'سيبروفلوكساسين', 'سيتريزين', 'سيفدينير', 'سيفوريوكسيم', 'سيفيكسيم', 'سيكلوسبورين', 'غوايفينيسين', 'فالبروات', 'فلوروميثولون', 'فوريكونازول', 'فيتامين د', 'قطرات بريدنيزولون', 'كارباشول', 'كاربامازيبين', 'كاربوسيستين', 'كبريتات الزنك', 'كربونات الكالسيوم', 'كلورامفينيكول', 'كلورهيكسيدين', 'كليندامايسين', 'كولاجين', 'كيتورولاك', 'لاتانوبروست', 'لوراتادين', 'ليدوكايين', 'ليفوفلوكساسين', 'ليفيتيجراست', 'ليفيتيراسيتام', 'مانيتول', 'مصل فيتامين سي', 'مكملات الحديد', 'موبيروسين', 'موكسيفلوكساسين', 'مونتيلوكاست', 'ميبيندازول', 'ميترونيدازول', 'ميتوكلوبراميد', 'ميمانتين', 'ناتاميسين', 'نياسيناميد', 'نيبافيناك', 'نيستاتين', 'هيالورونات الصوديوم', 'هيدروكسيزين', 'هيدروكورتيزون', 'هيدروكينون']\nEnglishWords=['Acetazolamide', 'Acetylcysteine', 'Albendazole', 'Amantadine', 'Amoxicillin', 'Artificial Tears', 'Atropine', 'Azithromycin', 'Bimatoprost', 'Botox', 'Brimonidine', 'Calcium Carbonate', 'Carbachol', 'Carbamazepine', 'Carbocisteine', 'Cefdinir', 'Cefixime', 'Cefuroxime', 'Cetirizine', 'Chloramphenicol', 'Chlorhexidine', 'Ciprofloxacin', 'Clindamycin', 'Collagen', 'Cyclosporine', 'Dexamethasone', 'Dextromethorphan', 'Diclofenac', 'Domperidone', 'Donepezil', 'Dorzolamide', 'Doxycycline', 'Erythromycin', 'Fluorometholone', 'Gabapentin', 'Gatifloxacin', 'Glycolic Acid', 'Guaifenesin', 'Hyaluronic Acid', 'Hydrocortisone', 'Hydroquinone', 'Hydroxyzine', 'Ibuprofen', 'Iron Supplements', 'Ketorolac', 'Lactic Acid', 'Latanoprost', 'Levetiracetam', 'Levofloxacin', 'Lidocaine', 'Lifitegrast', 'Loratadine', 'Mannitol', 'Mebendazole', 'Memantine', 'Metoclopramide', 'Metronidazole', 'Montelukast', 'Moxifloxacin', 'Multivitamins', 'Mupirocin', 'Natamycin', 'Nepafenac', 'Niacinamide', 'Nystatin', 'Ofloxacin', 'Omeprazole', 'Ondansetron', 'Oral Rehydration Salts', 'Paracetamol', 'Peptides', 'Pilocarpine', 'Pramipexole', 'Prednisolone', 'Prednisolone Acetate', 'Prednisolone Drops', 'Pregabalin', 'Probiotics', 'Ranitidine', 'Retinol', 'Rivastigmine', 'Ropinirole', 'Salbutamol', 'Salicylic Acid', 'Sodium Hyaluronate', 'Timolol', 'Tobramycin', 'Topiramate', 'Travoprost', 'Tretinoin', 'Tropicamide', 'Valproate', 'Vitamin C Serum', 'Vitamin D', 'Voriconazole', 'Zinc Sulfate''for', 'Every', 'After', 'Twice', 'needed', 'first', 'hours', 'breakfast', 'For', '8', 'awake', 'other', 'Night', 'hour', 'Morning', 'bed', '14', 'the', 'days', 'As', '5', 'bedtime', 'lunch', 'week', '7', 'daily', 'only', '4', 'Before', 'while', '3', 'minutes', '2', '6', 'day', '15', 'meals', 'Once', '12']\nfrequency_patterns = [\n    ## 🔹 English Frequencies\n    r\"\\bevery\\s\\d+\\shours?\\b\",            # \"every 6 hours\"\n    r\"\\bEvery\\shours\\b\",\n    r\"\\bevery\\s\\d+\\s?-\\s?\\d+\\shours?\\b\",  # \"every 4-6 hours\"\n    r\"\\bonce\\sdaily\\b\",                   # \"once daily\"\n    r\"\\btwice\\sdaily\\b\",                  # \"twice daily\"\n    r\"\\bthree\\stimes\\sa\\sday\\b\",          # \"three times a day\"\n    r\"\\bfour\\stimes\\sa\\sday\\b\",           # \"four times a day\"\n    r\"\\b\\d+\\stimes\\sa\\sday\\b\",            # \"5 times a day\"\n\n    ## ⏳ Time-Based\n    r\"\\bevery\\sother\\sday\\b\",             # \"every other day\"\n    r\"\\bevery\\s\\d+\\sdays?\\b\",             # \"every 3 days\"\n    r\"\\bevery\\s\\d+\\sweeks?\\b\",            # \"every 2 weeks\"\n    r\"\\bevery\\s\\d+\\smonths?\\b\",           # \"every 6 months\"\n\n    ## 🌙 Morning/Evening\n    r\"\\bin\\sthe\\smorning\\b\",              # \"in the morning\"\n    r\"\\bin\\sthe\\sevening\\b\",              # \"in the evening\"\n    r\"\\bin\\sthe\\safternoon\\b\",            # \"in the afternoon\"\n    r\"\\bin\\sthe\\snight\\b\",                # \"in the night\"\n    r\"\\bdaily\\sat\\snoon\\b\",               # \"daily at noon\"\n\n    ## 🍽 Meal-Based\n    r\"\\bbefore\\smeals?\\b\",                # \"before meals\"\n    r\"\\bbefore\\sbreakfast?\\b\",            # \"before breakfast\"\n    r\"\\bafter\\smeals?\\b\",                 # \"after meals\"\n    r\"\\bafter\\sbreakfast?\\b\",             # \"after breakfast\"\n    r\"\\bbefore\\sfood\\b\",                  # \"before food\"\n    r\"\\bafter\\sfood\\b\",                   # \"after food\"\n    r\"\\bon\\san\\sempty\\sstomach\\b\",        # \"on an empty stomach\"\n\n    ## 🌙 Sleep\n    r\"\\bbefore\\sbedtime\\b\",               # \"before bedtime\"\n    r\"\\bat\\sbedtime\\b\",                   # \"at bedtime\"\n    r\"\\bbefore\\sgoing\\sto\\sbed\\b\",        # \"before going to bed\"\n\n    ## 🔄 PRN (As Needed)\n    r\"\\bas\\sneeded\\b\",                    # \"as needed\"\n    r\"\\bif\\sneeded\\b\",                    # \"if needed\"\n    r\"\\bwhen\\snecessary\\b\",               # \"when necessary\"\n    r\"\\bwhen\\srequired\\b\",                # \"when required\"\n    r\"\\bwhen\\sfeeling\\spain\\b\",           # \"when feeling pain\"\n\n    ## 🚑 Perioperative\n    r\"\\bbefore\\ssurgery\\b\",               # \"before surgery\"\n    r\"\\bafter\\ssurgery\\b\",                # \"after surgery\"\n    r\"\\bbefore\\san\\soperation\\b\",         # \"before an operation\"\n    r\"\\bafter\\san\\soperation\\b\",          # \"after an operation\"\n\n    ## 🔹 Arabic Frequencies\n    r\"\\bكل\\s\\d+\\sساعة\\b\",              # \"كل 8 ساعات\" (every X hours)\n    r\"\\bكل\\s\\d+\\s?-\\s?\\d+\\sساعات?\\b\",  # \"كل 4-6 ساعات\" (every X-Y hours)\n    r\"\\bمرة\\sيوميا\\b\",                 # \"مرة يوميًا\" (once daily)\n    r\"\\bمرة\\sكل\\sيوم\\b\",               # \"مرة كل يوم\" (once per day)\n    r\"\\bمرة\\sيوميا\\b\",                 # \"مرة يوميا\" (once per day)\n    r\"\\bمرة\\sأسبوعيا\\b\",               # \"مرة أسبوعيًا\" (once weekly)\n    r\"\\bمرة\\sكل\\sأسبوع\\b\",             # \"مرة كل أسبوع\" (once per week)\n    r\"\\bمرة\\sشهريا\\b\",                 # \"مرة شهريًا\" (once monthly)\n    r\"\\bمرة\\sكل\\sشهر\\b\",               # \"مرة كل شهر\" (once per month)\n    r\"\\bمرتين\\sيوميا\\b\",               # \"مرتين يوميًا\" (twice daily)\n    r\"\\b\\d+\\sمرات?\\sيوميا\\b\",          # \"3 مرات يوميًا\" (multiple times daily)\n\n    ## ⏳ Time-Based\n    r\"\\bكل\\sيومين\\b\",                   # \"كل يومين\" (every other day)\n    r\"\\bكل\\s\\d+\\sأيام\\b\",               # \"كل 3 أيام\" (every X days)\n    r\"\\bكل\\s\\d+\\sأسابيع\\b\",             # \"كل 2 أسابيع\" (every X weeks)\n    r\"\\bكل\\s\\d+\\sشهور\\b\",               # \"كل 6 شهور\" (every X months)\n\n   ## Arabic (Word-Based Numbers)\n    r\"\\bكل\\sساعة\\b\",                     # \"كل واحدة ساعة\" (every one hour)\n    r\"\\bكل\\sساعتين\\b\",                   # \"كل اثنتين ساعة\" (every two hours)\n    r\"\\bكل\\sثلاث\\sساعات\\b\",               # \"كل ثلاث ساعات\" (every three hours)\n    r\"\\bكل\\sأربع\\sساعات\\b\",              # \"كل أربع ساعات\" (every four hours)\n    r\"\\bكل\\sخمس\\sساعات\\b\",               # \"كل خمس ساعات\" (every five hours)\n    r\"\\bكل\\sست\\sساعات\\b\",                # \"كل ست ساعات\" (every six hours)\n    r\"\\bكل\\sسبع\\sساعات\\b\",               # \"كل سبع ساعات\" (every seven hours)\n    r\"\\bكل\\sثماني\\sساعات\\b\",             # \"كل ثماني ساعات\" (every eight hours)\n    r\"\\bكل\\sتسع\\sساعات\\b\",               # \"كل تسع ساعات\" (every nine hours)\n    r\"\\bكل\\sعشر\\sساعات\\b\",               # \"كل عشر ساعات\" (every ten hours)\n    r\"\\bكل\\sإحدى\\sعشرة\\sساعة\\b\",         # \"كل إحدى عشرة ساعة\" (every 11 hours)\n    r\"\\bكل\\sاثنتي\\sعشرة\\sساعة\\b\",        # \"كل اثنتي عشرة ساعة\" (every 12 hours)\n\n    ## 🌙 Morning/Evening\n    r\"\\bفي\\sالصباح\\b\",                  # \"في الصباح\" (in the morning)\n    r\"\\bفي\\sالمساء\\b\",                  # \"في المساء\" (in the evening)\n    r\"\\bفي\\sالظهيرة\\b\",                 # \"في الظهيرة\" (at noon)\n    r\"\\bفي\\sالليل\\b\",                   # \"في الليل\" (at night)\n\n    ## 🍽 Meal-Based\n    r\"\\bقبل\\sالأكل\\b\",                  # \"قبل الأكل\" (before meals)\n    r\"\\bبعد\\sالأكل\\b\",                  # \"بعد الأكل\" (after meals)\n    r\"\\bقبل\\sالطعام\\b\",                 # \"قبل الطعام\" (before food)\n    r\"\\bبعد\\sالطعام\\b\",                 # \"بعد الطعام\" (after food)\n    r\"\\bعلى\\sمعدة\\sفارغة\\b\",            # \"على معدة فارغة\" (on an empty stomach)\n    r\"\\bعلى\\sالريق\\b\",                   # \"على الريق\" (fasting)\n\n    ## 🌙 Sleep\n    r\"\\bقبل\\sالنوم\\b\",                 # \"قبل النوم\" (before sleep)\n    r\"\\bعند\\sالنوم\\b\",                 # \"عند النوم\" (at bedtime)\n\n    ## 🔄 PRN (As Needed)\n    r\"\\bعند\\sاللزوم\\b\",                # \"عند اللزوم\" (as needed)\n    r\"\\bحسب\\sالحاجة\\b\",                # \"حسب الحاجة\" (as required)\n    r\"\\bإذا\\sاستدعت\\sالحاجة\\b\",         # \"إذا استدعت الحاجة\" (if necessary)\n    r\"\\bعند\\sالشعور\\sبالألم\\b\",          # \"عند الشعور بالألم\" (when feeling pain)\n\n    ## 🚑 Perioperative\n    r\"\\bقبل\\sالعملية\\b\",              # \"قبل العملية\" (before surgery)\n    r\"\\bبعد\\sالعملية\\b\",              # \"بعد العملية\" (after surgery)\n    r\"\\bقبل\\sالتدخل\\sالجراحي\\b\",     # \"قبل التدخل الجراحي\" (before an operation)\n    r\"\\bبعد\\sالتدخل\\sالجراحي\\b\",     # \"بعد التدخل الجراحي\" (after an operation)\n    r\"\\bEvery\\s\\d+\\shours?\\b\",            # \"Every 8 hours\" (capitalized)\n    r\"\\bEvery\\shours?\\b\",                 # \"Every hours\" (capitalized)\n    r\"\\bAfter\\slunch\\b\",                  # \"After lunch\" (capitalized)\n    r\"\\bOnce\\sdaily\\b\",                   # \"Once daily\" (capitalized)\n\n]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T17:56:29.923580Z","iopub.execute_input":"2025-04-16T17:56:29.923872Z","iopub.status.idle":"2025-04-16T17:58:23.945284Z","shell.execute_reply.started":"2025-04-16T17:56:29.923850Z","shell.execute_reply":"2025-04-16T17:58:23.944312Z"}},"outputs":[{"name":"stdout","text":"Collecting jiwer\n  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\nCollecting rapidfuzz>=3.9.7 (from jiwer)\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\nDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\nSuccessfully installed jiwer-3.1.0 rapidfuzz-3.13.0\nCollecting ultralytics\n  Downloading ultralytics-8.3.109-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.109-py3-none-any.whl (974 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.8/974.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.109 ultralytics-thop-2.0.14\nRequirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n","output_type":"stream"},{"name":"stderr","text":"2025-04-16 17:58:08.882424: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744826289.132199      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744826289.210441      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"MODEL_NAME = \"microsoft/trocr-base-handwritten\"\nprocessor = TrOCRProcessor.from_pretrained(MODEL_NAME) # Initialize the processor here\nnew_model = VisionEncoderDecoderModel.from_pretrained(MODEL_NAME)\nnew_model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\nnew_model.config.pad_token_id = processor.tokenizer.pad_token_id\nnew_model.load_state_dict(torch.load(\"/kaggle/input/trocr_finetune_weights_stp/pytorch/default/1/model_weights.pth\"))\nDEFAULT_FREQUENCY = \"Every 6 hours\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T17:58:23.946848Z","iopub.execute_input":"2025-04-16T17:58:23.947376Z","iopub.status.idle":"2025-04-16T17:58:46.616844Z","shell.execute_reply.started":"2025-04-16T17:58:23.947356Z","shell.execute_reply":"2025-04-16T17:58:46.615960Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/224 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ae236fc90b54d99a39fdeb7c369ead3"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b24c2b6fcbf48009366d4edf39091da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d89d3e5c484c4a618e01e85b5eba6f8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1064272362764a28a4856699d6f5b2f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83e9ddadd91e4a5fa1da87dd39e80215"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cf0964101224ebe9abcaa699f29087e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f266ed650d0d42ff8b486abd0c73b7c5"}},"metadata":{}},{"name":"stderr","text":"Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n  \"attention_probs_dropout_prob\": 0.0,\n  \"encoder_stride\": 16,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 768,\n  \"image_size\": 384,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"model_type\": \"vit\",\n  \"num_attention_heads\": 12,\n  \"num_channels\": 3,\n  \"num_hidden_layers\": 12,\n  \"patch_size\": 16,\n  \"pooler_act\": \"tanh\",\n  \"pooler_output_size\": 768,\n  \"qkv_bias\": false,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.51.1\"\n}\n\nConfig of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_cross_attention\": true,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": 0.0,\n  \"cross_attention_hidden_size\": 768,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 12,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"eos_token_id\": 2,\n  \"init_std\": 0.02,\n  \"is_decoder\": true,\n  \"layernorm_embedding\": true,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"trocr\",\n  \"pad_token_id\": 1,\n  \"scale_embedding\": false,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.51.1\",\n  \"use_cache\": false,\n  \"use_learned_position_embeddings\": true,\n  \"vocab_size\": 50265\n}\n\nSome weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c5810eab74c48babbd46917a2b5fc9f"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from sklearn.cluster import DBSCAN\n\ndef preprocess_for_trocr(cropped_image):\n    # Convert BGR (OpenCV) to RGB (PIL)\n    rgb_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n    pil_image = Image.fromarray(rgb_image)\n    return pil_image\n\ndef fuzzy_match(word, word_list, threshold=30):\n    result = process.extractOne(word, word_list, scorer=fuzz.ratio)\n    if result:\n        # Handle different versions of fuzzywuzzy\n        if isinstance(result, tuple) and len(result) >= 2:\n            match, score = result[0], result[1]  # Extract match and score\n            return match if score >= threshold else None\n    return None\n\ndef remove_duplicate_boxes(boxes, iou_threshold=0.8):\n    if len(boxes) == 0:\n        return []\n\n    # Convert boxes to (x1, y1, x2, y2) format\n    boxes = np.array(boxes)\n    x1 = boxes[:, 0]\n    y1 = boxes[:, 1]\n    x2 = boxes[:, 2]\n    y2 = boxes[:, 3]\n    # Compute the area of the bounding boxes\n    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n\n    # Sort the boxes by the bottom-right y-coordinate\n    indices = np.argsort(y2)\n    keep = []\n\n    while len(indices) > 0:\n        last = len(indices) - 1\n        i = indices[last]\n        keep.append(i)\n\n        # Compute the IoU of the remaining boxes with the last box\n        xx1 = np.maximum(x1[i], x1[indices[:last]])\n        yy1 = np.maximum(y1[i], y1[indices[:last]])\n        xx2 = np.minimum(x2[i], x2[indices[:last]])\n        yy2 = np.minimum(y2[i], y2[indices[:last]])\n\n        w = np.maximum(0, xx2 - xx1 + 1)\n        h = np.maximum(0, yy2 - yy1 + 1)\n        overlap = (w * h) / areas[indices[:last]]\n\n        # Remove boxes with IoU greater than the threshold\n        indices = np.delete(indices, np.concatenate(([last], np.where(overlap > iou_threshold)[0])))\n\n    return boxes[keep].tolist()\n\ndef group_boxes_into_lines_and_sort(boxes, texts, vertical_threshold=20):\n    if not boxes or not texts:\n        return [], []\n    \n    # Convert boxes to include center points and other useful metrics\n    box_data = []\n    for i, (box, text) in enumerate(zip(boxes, texts)):\n        if text:  # Only process boxes with valid text\n            x1, y1, x2, y2 = box\n            center_y = (y1 + y2) / 2\n            center_x = (x1 + x2) / 2\n            height = y2 - y1\n            box_data.append({\n                'index': i,\n                'box': box,\n                'text': text,\n                'center_x': center_x,\n                'center_y': center_y,\n                'height': height\n            })\n    \n    if not box_data:\n        return [], []\n    \n    # Dynamically adjust vertical threshold based on average text height\n    avg_height = sum(item['height'] for item in box_data) / len(box_data)\n    dynamic_threshold = max(vertical_threshold, avg_height * 0.7)\n    \n    # Initial sort by y-coordinate\n    box_data.sort(key=lambda x: x['center_y'])\n    \n    # Use DBSCAN clustering to group lines\n    points = np.array([[item['center_x'], item['center_y']] for item in box_data])\n    # Adjust eps based on average height\n    clustering = DBSCAN(eps=dynamic_threshold, min_samples=1).fit(points)\n    labels = clustering.labels_\n    \n    # Group boxes by cluster label\n    lines = {}\n    for i, label in enumerate(labels):\n        if label not in lines:\n            lines[label] = []\n        lines[label].append(box_data[i])\n    \n    # Sort lines by average y-coordinate\n    sorted_lines = sorted(lines.values(), key=lambda line: sum(item['center_y'] for item in line)/len(line))\n    \n    # Sort each line by x-coordinate (left to right)\n    for line in sorted_lines:\n        line.sort(key=lambda x: x['center_x'])\n    \n    # Extract the ordered text and boxes\n    ordered_text = []\n    ordered_boxes = []\n    for line in sorted_lines:\n        for box in line:\n            ordered_text.append(box['text'])\n            ordered_boxes.append(box['box'])\n    \n    return ordered_text, ordered_boxes\n\ndef TextExtraction(images):\n    extracted_data = []\n    for image_path in images:\n        image = cv2.imread(image_path)\n        image_data = {\n            \"image_path\": image_path,\n            \"text\": \"\",  # Full text in reading order\n            \"words\": []  # List to store {text, position} for each word\n        }\n        \n        # Run YOLOv8 detection\n        results = model(image)\n        boxes = results[0].boxes.xyxy.cpu().numpy()\n        class_ids = results[0].boxes.cls.cpu().numpy()\n        \n        # Remove duplicate boxes\n        boxes = remove_duplicate_boxes(boxes)\n        \n        # Extract text from each box\n        all_texts = []\n        for i, box in enumerate(boxes):\n            x1, y1, x2, y2 = map(int, box)\n            cropped_image = image[y1:y2, x1:x2]\n            \n            # Preprocess for TrOCR\n            trocr_input = preprocess_for_trocr(cropped_image)\n            inputs = processor(images=trocr_input, return_tensors=\"pt\").to(new_model.device)\n            \n            # Extract text\n            with torch.no_grad():\n                generated_ids = new_model.generate(**inputs)\n                output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n            \n            # Fuzzy match with language-specific dictionary\n            class_id = int(class_ids[i])\n            word_list = ArabicWords if class_id == 0 else EnglishWords\n            matched_text = fuzzy_match(output_text.strip(), word_list)\n            if matched_text:\n                all_texts.append(matched_text)\n                # Save the original box for later\n                boxes[i] = box  # Ensure box is in the right format\n        \n        # Group into lines and sort in reading order\n        ordered_texts, ordered_boxes = group_boxes_into_lines_and_sort(boxes, all_texts)\n        \n        # Build the complete text and word objects\n        full_text = \" \".join(ordered_texts)\n        image_data[\"text\"] = full_text\n        \n        for text, box in zip(ordered_texts, ordered_boxes):\n            x1, y1, x2, y2 = map(int, box)\n            image_data[\"words\"].append({\n                \"text\": text,\n                \"position\": (x1, y1, x2, y2)\n            })\n        \n        extracted_data.append(image_data)\n    \n    return extracted_data\n\ndef sort_words_by_position(word_data):\n    # Sort by y1 (top-to-bottom), then by x1 (left-to-right)\n    return sorted(word_data, key=lambda x: (x[\"position\"][1], x[\"position\"][0]))\n\ndef print_sorted_words(sorted_words):\n    print(\"Sorted Words (Top-to-Bottom, Left-to-Right):\")\n    for i, word in enumerate(sorted_words):\n        print(f\"{i+1}: '{word['text']}' at {word['position']}\")\n\ndef organize_medication_instructions(words_with_coords):\n    # Step 1: Calculate the center y-coordinate for each word's bounding box\n    words_with_y_center = []\n    for word_dict in words_with_coords:\n        word = word_dict['text']\n        coords = word_dict['position']  # Assuming this is (x1, y1, x2, y2)\n        x1, y1, x2, y2 = coords\n        y_center = (y1 + y2) / 2\n        x_center = (x1 + x2) / 2\n        words_with_y_center.append((word, y_center, x_center, coords))\n    \n    # Step 2: Sort words by their y-coordinate (top to bottom)\n    words_with_y_center.sort(key=lambda x: x[1])\n    \n    # Step 3: Group words that are likely on the same line\n    # We'll consider words to be on the same line if their y-centers are within a threshold\n    y_threshold = 100  # This can be adjusted based on your document's layout\n    \n    lines = []\n    current_line = [words_with_y_center[0]]\n    \n    for i in range(1, len(words_with_y_center)):\n        current_word = words_with_y_center[i]\n        previous_word = words_with_y_center[i-1]\n        \n        # If this word is close in y-position to the previous word, add it to the current line\n        if abs(current_word[1] - previous_word[1]) < y_threshold:\n            current_line.append(current_word)\n        # Otherwise, start a new line\n        else:\n            lines.append(current_line)\n            current_line = [current_word]\n    \n    # Add the last line if it's not empty\n    if current_line:\n        lines.append(current_line)\n    \n    # Step 4: Sort words within each line by x-coordinate (left to right)\n    for i in range(len(lines)):\n        lines[i].sort(key=lambda x: x[2])  # Sort by x_center\n    \n    # Step 5: Join words in each line to form complete instructions\n    instructions = []\n    for line in lines:\n        instruction = \" \".join(word[0] for word in line)\n        instructions.append(instruction)\n    \n    return instructions\n\ndef create_medication_frequency_pairs(organized_instructions):\n    # Step 1: Concatenate all instructions into one line\n    all_text = \" \".join(organized_instructions)\n    \n    \n    # Step 3: Extract medication-frequency pairs\n    medication_pairs = []\n    \n    # Simple approach: Find a medication and assume text until the next medication is its frequency\n    for i, med in enumerate(medicine_list):\n        match = re.search(r'\\b' + med + r'\\b', all_text, re.IGNORECASE)\n        if match:\n            start_idx = match.start()\n            \n            # Find the next medication in the text after this one\n            next_med_idx = float('inf')\n            for other_med in medicine_list:\n                if other_med != med:\n                    other_match = re.search(r'\\b' + other_med + r'\\b', all_text[start_idx+len(med):], re.IGNORECASE)\n                    if other_match:\n                        if start_idx + len(med) + other_match.start() < next_med_idx:\n                            next_med_idx = start_idx + len(med) + other_match.start()\n            \n            # Extract the frequency instruction\n            if next_med_idx != float('inf'):\n                frequency = all_text[start_idx+len(med):next_med_idx].strip()\n            else:\n                frequency = all_text[start_idx+len(med):].strip()\n            \n            medication_pairs.append((med, frequency))\n    \n    # Step 4: More sophisticated approach using patterns specific to medication instructions\n    if not medication_pairs:\n        # Pattern: Look for medication name followed by frequency info\n        patterns = [\n            # Medication followed by \"Every X hours\"\n            (r'(\\b\\w+\\b)\\s+Every\\s+(\\d+)\\s+hours', lambda m: (m.group(1), f\"Every {m.group(2)} hours\")),\n            \n            # Medication followed by \"Once daily\"\n            (r'(\\b\\w+\\b)\\s+Once\\s+daily', lambda m: (m.group(1), \"Once daily\")),\n            \n            # Medication followed by \"After lunch\"\n            (r'(\\b\\w+\\b)\\s+After\\s+lunch', lambda m: (m.group(1), \"After lunch\")),\n            \n            # More patterns can be added for different frequency formats\n        ]\n        \n        for pattern, extract_func in patterns:\n            for match in re.finditer(pattern, all_text, re.IGNORECASE):\n                medication_pairs.append(extract_func(match))\n    \n    return medication_pairs\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T18:04:42.857594Z","iopub.execute_input":"2025-04-16T18:04:42.858341Z","iopub.status.idle":"2025-04-16T18:04:43.276252Z","shell.execute_reply.started":"2025-04-16T18:04:42.858313Z","shell.execute_reply":"2025-04-16T18:04:43.275401Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def submit(images):\n    results = [] \n    extracted_data = TextExtraction(images)\n\n    for prescription_data in extracted_data:\n        sorted_words = sort_words_by_position(prescription_data[\"words\"])\n        print(f\"\\nSorted words for {prescription_data['image_path']}:\")\n        print_sorted_words(sorted_words)\n        print(\"-------------------------------------------------------------------------------\")\n        organized_instructions = organize_medication_instructions(sorted_words)\n\n        print(\"Organized Medication Instructions:\")\n        for i, instruction in enumerate(organized_instructions, 1):\n            print(f\"{i}. {instruction}\")\n        print(\"-------------------------------------------------------------------------------\")\n        medication_pairs = create_medication_frequency_pairs(organized_instructions)\n\n        print(\"\\nMedication-Frequency Pairs:\")\n        for med, freq in medication_pairs:\n            print(f\"- {med}: {freq}\")\n        results.append({\n            \"image_path\": prescription_data[\"image_path\"],\n            \"prescription_pairs\": medication_pairs\n        })\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T18:05:41.970036Z","iopub.execute_input":"2025-04-16T18:05:41.970381Z","iopub.status.idle":"2025-04-16T18:05:41.975915Z","shell.execute_reply.started":"2025-04-16T18:05:41.970359Z","shell.execute_reply":"2025-04-16T18:05:41.975251Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Example list of image file paths (update with actual paths)\nimages = ['/kaggle/input/machathon6-phase1-images/Beauty_prescription_104.jpg','/kaggle/input/machathon6-phase1-images/Beauty_prescription_116.jpg','/kaggle/input/machathon6-phase1-images/Dental_prescription_591.jpg', '/kaggle/input/machathon6-phase1-images/Neurology_prescription_131.jpg']\n\n# Call the submit function\nresults = submit(images)\n\n# Print the structured results\nfor i, result in enumerate(results):\n    print(f\"\\nPrescription {i + 1} ({result['image_path']}):\")\n    if not result[\"prescription_pairs\"]:\n        print(\"  No medicine-frequency pairs found\")\n    else:\n        for medicine, frequency in result[\"prescription_pairs\"]:\n            print(f\"  Medicine: {medicine}, Frequency: {frequency}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}