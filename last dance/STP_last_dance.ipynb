{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10973556,"sourceType":"datasetVersion","datasetId":6700028},{"sourceId":316767,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":267330,"modelId":288386},{"sourceId":280452,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":240279,"modelId":261927}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install jiwer\n!pip install ultralytics\n!pip install fuzzywuzzy\nimport os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torchvision.transforms as transforms\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, TrOCRProcessor, VisionEncoderDecoderModel\nfrom google.colab import drive\nimport gdown\nfrom ultralytics import YOLO\nimport re\nfrom rapidfuzz import fuzz, process\nimport matplotlib.pyplot as plt\nfrom google.colab.patches import cv2_imshow\nfrom PIL import Image\nimport torch\n#yoloV8 wieghts\nmodel = YOLO(\"/kaggle/input/yolo-weights-word-detection/pytorch/default/1/worddetection.pt\")  # Path to your downloaded weights\n\n\nmedicine_list=['Acetazolamide', 'Acetylcysteine', 'Albendazole', 'Amantadine', 'Amoxicillin', 'Artificial Tears', 'Atropine', 'Azithromycin', 'Bimatoprost', 'Botox', 'Brimonidine', 'Calcium Carbonate', 'Carbachol', 'Carbamazepine', 'Carbocisteine', 'Cefdinir', 'Cefixime', 'Cefuroxime', 'Cetirizine', 'Chloramphenicol', 'Chlorhexidine', 'Ciprofloxacin', 'Clindamycin', 'Collagen', 'Cyclosporine', 'Dexamethasone', 'Dextromethorphan', 'Diclofenac', 'Domperidone', 'Donepezil', 'Dorzolamide', 'Doxycycline', 'Erythromycin', 'Fluorometholone', 'Gabapentin', 'Gatifloxacin', 'Glycolic Acid', 'Guaifenesin', 'Hyaluronic Acid', 'Hydrocortisone', 'Hydroquinone', 'Hydroxyzine', 'Ibuprofen', 'Iron Supplements', 'Ketorolac', 'Lactic Acid', 'Latanoprost', 'Levetiracetam', 'Levofloxacin', 'Lidocaine', 'Lifitegrast', 'Loratadine', 'Mannitol', 'Mebendazole', 'Memantine', 'Metoclopramide', 'Metronidazole', 'Montelukast', 'Moxifloxacin', 'Multivitamins', 'Mupirocin', 'Natamycin', 'Nepafenac', 'Niacinamide', 'Nystatin', 'Ofloxacin', 'Omeprazole', 'Ondansetron', 'Oral Rehydration Salts', 'Paracetamol', 'Peptides', 'Pilocarpine', 'Pramipexole', 'Prednisolone', 'Prednisolone Acetate', 'Prednisolone Drops', 'Pregabalin', 'Probiotics', 'Ranitidine', 'Retinol', 'Rivastigmine', 'Ropinirole', 'Salbutamol', 'Salicylic Acid', 'Sodium Hyaluronate', 'Timolol', 'Tobramycin', 'Topiramate', 'Travoprost', 'Tretinoin', 'Tropicamide', 'Valproate', 'Vitamin C Serum', 'Vitamin D', 'Voriconazole', 'Zinc Sulfate', 'Ø£ØªØ±ÙˆØ¨ÙŠÙ†', 'Ø£Ø²ÙŠØ«Ø±ÙˆÙ…ÙŠØ³ÙŠÙ†', 'Ø£Ø³ÙŠØªØ§Øª Ø§Ù„Ø¨Ø±ÙŠØ¯Ù†ÙŠØ²ÙˆÙ„ÙˆÙ†', 'Ø£Ø³ÙŠØªØ§Ø²ÙˆÙ„Ø§Ù…ÙŠØ¯', 'Ø£Ø³ÙŠØªÙŠÙ„ Ø³ÙŠØ³ØªÙŠÙ†', 'Ø£Ù„Ø¨ÙŠÙ†Ø¯Ø§Ø²ÙˆÙ„', 'Ø£Ù…Ø§Ù†ØªØ§Ø¯ÙŠÙ†', 'Ø£Ù…Ù„Ø§Ø­ Ø§Ù„Ø¥Ù…Ø§Ù‡Ø© Ø§Ù„ÙÙ…ÙˆÙŠØ©', 'Ø£Ù…ÙˆÙƒØ³ÙŠØ³ÙŠÙ„ÙŠÙ†', 'Ø£ÙˆÙÙ„ÙˆÙƒØ³Ø§Ø³ÙŠÙ†', 'Ø£ÙˆÙ…ÙŠØ¨Ø±Ø§Ø²ÙˆÙ„', 'Ø£ÙˆÙ†Ø¯Ø§Ù†Ø³ÙŠØªØ±ÙˆÙ†', 'Ø¥Ø±ÙŠØ«Ø±ÙˆÙ…Ø§ÙŠØ³ÙŠÙ†', 'Ø¥ÙŠØ¨ÙˆØ¨Ø±ÙˆÙÙŠÙ†', 'Ø§Ù„Ø¨Ø¨ØªÙŠØ¯Ø§Øª', 'Ø§Ù„Ø¨Ø±ÙˆØ¨ÙŠÙˆØªÙŠÙƒ', 'Ø§Ù„Ø¨ÙˆØªÙˆÙƒØ³', 'Ø§Ù„ÙÙŠØªØ§Ù…ÙŠÙ†Ø§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©', 'Ø¨Ø§Ø±Ø§Ø³ÙŠØªØ§Ù…ÙˆÙ„', 'Ø¨Ø±Ø§Ù…ÙŠØ¨ÙŠÙƒØ³ÙˆÙ„', 'Ø¨Ø±ÙŠØ¬Ø§Ø¨Ø§Ù„ÙŠÙ†', 'Ø¨Ø±ÙŠØ¯Ù†ÙŠØ²ÙˆÙ„ÙˆÙ†', 'Ø¨Ø±ÙŠÙ…ÙˆÙ†ÙŠØ¯ÙŠÙ†', 'Ø¨ÙŠÙ„ÙˆÙƒØ§Ø±Ø¨ÙŠÙ†', 'Ø¨ÙŠÙ…Ø§ØªÙˆØ¨Ø±ÙˆØ³Øª', 'ØªØ±Ø§ÙÙˆØ¨Ø±ÙˆØ³Øª', 'ØªØ±ÙˆØ¨ÙŠÙƒØ§Ù…ÙŠØ¯', 'ØªØ±ÙŠØªÙŠÙ†ÙˆÙŠÙ†', 'ØªÙˆØ¨Ø±Ø§Ù…ÙŠØ³ÙŠÙ†', 'ØªÙˆØ¨ÙŠØ±Ø§Ù…ÙŠØª', 'ØªÙŠÙ…ÙˆÙ„ÙˆÙ„', 'Ø¬Ø§Ø¨Ø§Ø¨Ù†ØªÙŠÙ†', 'Ø¬Ø§ØªÙŠÙÙ„ÙˆÙƒØ³Ø§Ø³ÙŠÙ†', 'Ø­Ù…Ø¶ Ø§Ù„Ø¬Ù„ÙŠÙƒÙˆÙ„ÙŠÙƒ', 'Ø­Ù…Ø¶ Ø§Ù„Ø³Ø§Ù„ÙŠØ³ÙŠÙ„ÙŠÙƒ', 'Ø­Ù…Ø¶ Ø§Ù„Ù„Ø§ÙƒØªÙŠÙƒ', 'Ø­Ù…Ø¶ Ø§Ù„Ù‡ÙŠØ§Ù„ÙˆØ±ÙˆÙ†ÙŠÙƒ', 'Ø¯Ù…ÙˆØ¹ ØµÙ†Ø§Ø¹ÙŠØ©', 'Ø¯ÙˆØ±Ø²ÙˆÙ„Ø§Ù…ÙŠØ¯', 'Ø¯ÙˆÙƒØ³ÙŠØ³ÙŠÙƒÙ„ÙŠÙ†', 'Ø¯ÙˆÙ…Ø¨ÙŠØ±ÙŠØ¯ÙˆÙ†', 'Ø¯ÙˆÙ†ÙŠØ¨ÙŠØ²ÙŠÙ„', 'Ø¯ÙŠÙƒØ³Ø§Ù…ÙŠØ«Ø§Ø²ÙˆÙ†', 'Ø¯ÙŠÙƒØ³ØªØ±ÙˆÙ…ÙŠØ«ÙˆØ±ÙØ§Ù†', 'Ø¯ÙŠÙƒÙ„ÙˆÙÙŠÙ†Ø§Ùƒ', 'Ø±Ø§Ù†ÙŠØªÙŠØ¯ÙŠÙ†', 'Ø±ÙˆØ¨ÙŠÙ†ÙŠØ±ÙˆÙ„', 'Ø±ÙŠØªÙŠÙ†ÙˆÙ„', 'Ø±ÙŠÙØ§Ø³ØªØ¬Ù…ÙŠÙ†', 'Ø³Ø§Ù„Ø¨ÙŠÙˆØªØ§Ù…ÙˆÙ„', 'Ø³ÙŠØ¨Ø±ÙˆÙÙ„ÙˆÙƒØ³Ø§Ø³ÙŠÙ†', 'Ø³ÙŠØªØ±ÙŠØ²ÙŠÙ†', 'Ø³ÙŠÙØ¯ÙŠÙ†ÙŠØ±', 'Ø³ÙŠÙÙˆØ±ÙŠÙˆÙƒØ³ÙŠÙ…', 'Ø³ÙŠÙÙŠÙƒØ³ÙŠÙ…', 'Ø³ÙŠÙƒÙ„ÙˆØ³Ø¨ÙˆØ±ÙŠÙ†', 'ØºÙˆØ§ÙŠÙÙŠÙ†ÙŠØ³ÙŠÙ†', 'ÙØ§Ù„Ø¨Ø±ÙˆØ§Øª', 'ÙÙ„ÙˆØ±ÙˆÙ…ÙŠØ«ÙˆÙ„ÙˆÙ†', 'ÙÙˆØ±ÙŠÙƒÙˆÙ†Ø§Ø²ÙˆÙ„', 'ÙÙŠØªØ§Ù…ÙŠÙ† Ø¯', 'Ù‚Ø·Ø±Ø§Øª Ø¨Ø±ÙŠØ¯Ù†ÙŠØ²ÙˆÙ„ÙˆÙ†', 'ÙƒØ§Ø±Ø¨Ø§Ø´ÙˆÙ„', 'ÙƒØ§Ø±Ø¨Ø§Ù…Ø§Ø²ÙŠØ¨ÙŠÙ†', 'ÙƒØ§Ø±Ø¨ÙˆØ³ÙŠØ³ØªÙŠÙ†', 'ÙƒØ¨Ø±ÙŠØªØ§Øª Ø§Ù„Ø²Ù†Ùƒ', 'ÙƒØ±Ø¨ÙˆÙ†Ø§Øª Ø§Ù„ÙƒØ§Ù„Ø³ÙŠÙˆÙ…', 'ÙƒÙ„ÙˆØ±Ø§Ù…ÙÙŠÙ†ÙŠÙƒÙˆÙ„', 'ÙƒÙ„ÙˆØ±Ù‡ÙŠÙƒØ³ÙŠØ¯ÙŠÙ†', 'ÙƒÙ„ÙŠÙ†Ø¯Ø§Ù…Ø§ÙŠØ³ÙŠÙ†', 'ÙƒÙˆÙ„Ø§Ø¬ÙŠÙ†', 'ÙƒÙŠØªÙˆØ±ÙˆÙ„Ø§Ùƒ', 'Ù„Ø§ØªØ§Ù†ÙˆØ¨Ø±ÙˆØ³Øª', 'Ù„ÙˆØ±Ø§ØªØ§Ø¯ÙŠÙ†', 'Ù„ÙŠØ¯ÙˆÙƒØ§ÙŠÙŠÙ†', 'Ù„ÙŠÙÙˆÙÙ„ÙˆÙƒØ³Ø§Ø³ÙŠÙ†', 'Ù„ÙŠÙÙŠØªÙŠØ¬Ø±Ø§Ø³Øª', 'Ù„ÙŠÙÙŠØªÙŠØ±Ø§Ø³ÙŠØªØ§Ù…', 'Ù…Ø§Ù†ÙŠØªÙˆÙ„', 'Ù…ØµÙ„ ÙÙŠØªØ§Ù…ÙŠÙ† Ø³ÙŠ', 'Ù…ÙƒÙ…Ù„Ø§Øª Ø§Ù„Ø­Ø¯ÙŠØ¯', 'Ù…ÙˆØ¨ÙŠØ±ÙˆØ³ÙŠÙ†', 'Ù…ÙˆÙƒØ³ÙŠÙÙ„ÙˆÙƒØ³Ø§Ø³ÙŠÙ†', 'Ù…ÙˆÙ†ØªÙŠÙ„ÙˆÙƒØ§Ø³Øª', 'Ù…ÙŠØ¨ÙŠÙ†Ø¯Ø§Ø²ÙˆÙ„', 'Ù…ÙŠØªØ±ÙˆÙ†ÙŠØ¯Ø§Ø²ÙˆÙ„', 'Ù…ÙŠØªÙˆÙƒÙ„ÙˆØ¨Ø±Ø§Ù…ÙŠØ¯', 'Ù…ÙŠÙ…Ø§Ù†ØªÙŠÙ†', 'Ù†Ø§ØªØ§Ù…ÙŠØ³ÙŠÙ†', 'Ù†ÙŠØ§Ø³ÙŠÙ†Ø§Ù…ÙŠØ¯', 'Ù†ÙŠØ¨Ø§ÙÙŠÙ†Ø§Ùƒ', 'Ù†ÙŠØ³ØªØ§ØªÙŠÙ†', 'Ù‡ÙŠØ§Ù„ÙˆØ±ÙˆÙ†Ø§Øª Ø§Ù„ØµÙˆØ¯ÙŠÙˆÙ…', 'Ù‡ÙŠØ¯Ø±ÙˆÙƒØ³ÙŠØ²ÙŠÙ†', 'Ù‡ÙŠØ¯Ø±ÙˆÙƒÙˆØ±ØªÙŠØ²ÙˆÙ†', 'Ù‡ÙŠØ¯Ø±ÙˆÙƒÙŠÙ†ÙˆÙ†']\nArabicWords=['Ù¨', 'Ø¯Ù‚Ø§Ø¦Ù‚', 'Ù¡Ù¢', 'Ù‚Ø¨Ù„', 'Ø§Ù„Ø£ÙƒÙ„', 'Ø£Ø³Ø¨ÙˆØ¹', 'Ù¥', 'Ø§Ù„Ù†ÙˆÙ…', 'Ù„ÙŠÙ„Ø§', 'Ø³Ø§Ø¹Ø§Øª', 'Ù„Ø£ÙˆÙ„', 'ÙŠÙˆÙ…', 'Ù…Ø±Ø©', 'Ø§Ù„ÙŠÙ‚Ø¸Ø©', 'Ù¤', 'ÙƒÙ„', 'Ù§', 'Ø¯Ù‚ÙŠÙ‚Ø©', 'Ø£Ø«Ù†Ø§Ø¡', 'Ù£', 'Ù¦', 'ÙŠÙˆÙ…ÙŠÙ†', 'Ø§Ù„ÙØ·Ø§Ø±', 'Ù…Ø±ØªÙŠÙ†', 'Ù¡Ù¤', 'ÙˆØ§Ø­Ø¯Ø©', 'Ø£ÙŠØ§Ù…', 'Ø§Ù„ØºØ¯Ø§Ø¡', 'Ø§Ù„Ù„Ø²ÙˆÙ…', 'Ø³Ø§Ø¹Ø©', 'Ù„Ù…Ø¯Ø©', 'ÙŠÙˆÙ…ÙŠØ§', 'Ø¨Ø¹Ø¯', 'ÙÙ‚Ø·', 'ØµØ¨Ø§Ø­Ø§', 'Ø¹Ù†Ø¯', 'Ù¡Ù¥' ,'Ø£ØªØ±ÙˆØ¨ÙŠÙ†', 'Ø£Ø²ÙŠØ«Ø±ÙˆÙ…ÙŠØ³ÙŠÙ†', 'Ø£Ø³ÙŠØªØ§Øª Ø§Ù„Ø¨Ø±ÙŠØ¯Ù†ÙŠØ²ÙˆÙ„ÙˆÙ†', 'Ø£Ø³ÙŠØªØ§Ø²ÙˆÙ„Ø§Ù…ÙŠØ¯', 'Ø£Ø³ÙŠØªÙŠÙ„ Ø³ÙŠØ³ØªÙŠÙ†', 'Ø£Ù„Ø¨ÙŠÙ†Ø¯Ø§Ø²ÙˆÙ„', 'Ø£Ù…Ø§Ù†ØªØ§Ø¯ÙŠÙ†', 'Ø£Ù…Ù„Ø§Ø­ Ø§Ù„Ø¥Ù…Ø§Ù‡Ø© Ø§Ù„ÙÙ…ÙˆÙŠØ©', 'Ø£Ù…ÙˆÙƒØ³ÙŠØ³ÙŠÙ„ÙŠÙ†', 'Ø£ÙˆÙÙ„ÙˆÙƒØ³Ø§Ø³ÙŠÙ†', 'Ø£ÙˆÙ…ÙŠØ¨Ø±Ø§Ø²ÙˆÙ„', 'Ø£ÙˆÙ†Ø¯Ø§Ù†Ø³ÙŠØªØ±ÙˆÙ†', 'Ø¥Ø±ÙŠØ«Ø±ÙˆÙ…Ø§ÙŠØ³ÙŠÙ†', 'Ø¥ÙŠØ¨ÙˆØ¨Ø±ÙˆÙÙŠÙ†', 'Ø§Ù„Ø¨Ø¨ØªÙŠØ¯Ø§Øª', 'Ø§Ù„Ø¨Ø±ÙˆØ¨ÙŠÙˆØªÙŠÙƒ', 'Ø§Ù„Ø¨ÙˆØªÙˆÙƒØ³', 'Ø§Ù„ÙÙŠØªØ§Ù…ÙŠÙ†Ø§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©', 'Ø¨Ø§Ø±Ø§Ø³ÙŠØªØ§Ù…ÙˆÙ„', 'Ø¨Ø±Ø§Ù…ÙŠØ¨ÙŠÙƒØ³ÙˆÙ„', 'Ø¨Ø±ÙŠØ¬Ø§Ø¨Ø§Ù„ÙŠÙ†', 'Ø¨Ø±ÙŠØ¯Ù†ÙŠØ²ÙˆÙ„ÙˆÙ†', 'Ø¨Ø±ÙŠÙ…ÙˆÙ†ÙŠØ¯ÙŠÙ†', 'Ø¨ÙŠÙ„ÙˆÙƒØ§Ø±Ø¨ÙŠÙ†', 'Ø¨ÙŠÙ…Ø§ØªÙˆØ¨Ø±ÙˆØ³Øª', 'ØªØ±Ø§ÙÙˆØ¨Ø±ÙˆØ³Øª', 'ØªØ±ÙˆØ¨ÙŠÙƒØ§Ù…ÙŠØ¯', 'ØªØ±ÙŠØªÙŠÙ†ÙˆÙŠÙ†', 'ØªÙˆØ¨Ø±Ø§Ù…ÙŠØ³ÙŠÙ†', 'ØªÙˆØ¨ÙŠØ±Ø§Ù…ÙŠØª', 'ØªÙŠÙ…ÙˆÙ„ÙˆÙ„', 'Ø¬Ø§Ø¨Ø§Ø¨Ù†ØªÙŠÙ†', 'Ø¬Ø§ØªÙŠÙÙ„ÙˆÙƒØ³Ø§Ø³ÙŠÙ†', 'Ø­Ù…Ø¶ Ø§Ù„Ø¬Ù„ÙŠÙƒÙˆÙ„ÙŠÙƒ', 'Ø­Ù…Ø¶ Ø§Ù„Ø³Ø§Ù„ÙŠØ³ÙŠÙ„ÙŠÙƒ', 'Ø­Ù…Ø¶ Ø§Ù„Ù„Ø§ÙƒØªÙŠÙƒ', 'Ø­Ù…Ø¶ Ø§Ù„Ù‡ÙŠØ§Ù„ÙˆØ±ÙˆÙ†ÙŠÙƒ', 'Ø¯Ù…ÙˆØ¹ ØµÙ†Ø§Ø¹ÙŠØ©', 'Ø¯ÙˆØ±Ø²ÙˆÙ„Ø§Ù…ÙŠØ¯', 'Ø¯ÙˆÙƒØ³ÙŠØ³ÙŠÙƒÙ„ÙŠÙ†', 'Ø¯ÙˆÙ…Ø¨ÙŠØ±ÙŠØ¯ÙˆÙ†', 'Ø¯ÙˆÙ†ÙŠØ¨ÙŠØ²ÙŠÙ„', 'Ø¯ÙŠÙƒØ³Ø§Ù…ÙŠØ«Ø§Ø²ÙˆÙ†', 'Ø¯ÙŠÙƒØ³ØªØ±ÙˆÙ…ÙŠØ«ÙˆØ±ÙØ§Ù†', 'Ø¯ÙŠÙƒÙ„ÙˆÙÙŠÙ†Ø§Ùƒ', 'Ø±Ø§Ù†ÙŠØªÙŠØ¯ÙŠÙ†', 'Ø±ÙˆØ¨ÙŠÙ†ÙŠØ±ÙˆÙ„', 'Ø±ÙŠØªÙŠÙ†ÙˆÙ„', 'Ø±ÙŠÙØ§Ø³ØªØ¬Ù…ÙŠÙ†', 'Ø³Ø§Ù„Ø¨ÙŠÙˆØªØ§Ù…ÙˆÙ„', 'Ø³ÙŠØ¨Ø±ÙˆÙÙ„ÙˆÙƒØ³Ø§Ø³ÙŠÙ†', 'Ø³ÙŠØªØ±ÙŠØ²ÙŠÙ†', 'Ø³ÙŠÙØ¯ÙŠÙ†ÙŠØ±', 'Ø³ÙŠÙÙˆØ±ÙŠÙˆÙƒØ³ÙŠÙ…', 'Ø³ÙŠÙÙŠÙƒØ³ÙŠÙ…', 'Ø³ÙŠÙƒÙ„ÙˆØ³Ø¨ÙˆØ±ÙŠÙ†', 'ØºÙˆØ§ÙŠÙÙŠÙ†ÙŠØ³ÙŠÙ†', 'ÙØ§Ù„Ø¨Ø±ÙˆØ§Øª', 'ÙÙ„ÙˆØ±ÙˆÙ…ÙŠØ«ÙˆÙ„ÙˆÙ†', 'ÙÙˆØ±ÙŠÙƒÙˆÙ†Ø§Ø²ÙˆÙ„', 'ÙÙŠØªØ§Ù…ÙŠÙ† Ø¯', 'Ù‚Ø·Ø±Ø§Øª Ø¨Ø±ÙŠØ¯Ù†ÙŠØ²ÙˆÙ„ÙˆÙ†', 'ÙƒØ§Ø±Ø¨Ø§Ø´ÙˆÙ„', 'ÙƒØ§Ø±Ø¨Ø§Ù…Ø§Ø²ÙŠØ¨ÙŠÙ†', 'ÙƒØ§Ø±Ø¨ÙˆØ³ÙŠØ³ØªÙŠÙ†', 'ÙƒØ¨Ø±ÙŠØªØ§Øª Ø§Ù„Ø²Ù†Ùƒ', 'ÙƒØ±Ø¨ÙˆÙ†Ø§Øª Ø§Ù„ÙƒØ§Ù„Ø³ÙŠÙˆÙ…', 'ÙƒÙ„ÙˆØ±Ø§Ù…ÙÙŠÙ†ÙŠÙƒÙˆÙ„', 'ÙƒÙ„ÙˆØ±Ù‡ÙŠÙƒØ³ÙŠØ¯ÙŠÙ†', 'ÙƒÙ„ÙŠÙ†Ø¯Ø§Ù…Ø§ÙŠØ³ÙŠÙ†', 'ÙƒÙˆÙ„Ø§Ø¬ÙŠÙ†', 'ÙƒÙŠØªÙˆØ±ÙˆÙ„Ø§Ùƒ', 'Ù„Ø§ØªØ§Ù†ÙˆØ¨Ø±ÙˆØ³Øª', 'Ù„ÙˆØ±Ø§ØªØ§Ø¯ÙŠÙ†', 'Ù„ÙŠØ¯ÙˆÙƒØ§ÙŠÙŠÙ†', 'Ù„ÙŠÙÙˆÙÙ„ÙˆÙƒØ³Ø§Ø³ÙŠÙ†', 'Ù„ÙŠÙÙŠØªÙŠØ¬Ø±Ø§Ø³Øª', 'Ù„ÙŠÙÙŠØªÙŠØ±Ø§Ø³ÙŠØªØ§Ù…', 'Ù…Ø§Ù†ÙŠØªÙˆÙ„', 'Ù…ØµÙ„ ÙÙŠØªØ§Ù…ÙŠÙ† Ø³ÙŠ', 'Ù…ÙƒÙ…Ù„Ø§Øª Ø§Ù„Ø­Ø¯ÙŠØ¯', 'Ù…ÙˆØ¨ÙŠØ±ÙˆØ³ÙŠÙ†', 'Ù…ÙˆÙƒØ³ÙŠÙÙ„ÙˆÙƒØ³Ø§Ø³ÙŠÙ†', 'Ù…ÙˆÙ†ØªÙŠÙ„ÙˆÙƒØ§Ø³Øª', 'Ù…ÙŠØ¨ÙŠÙ†Ø¯Ø§Ø²ÙˆÙ„', 'Ù…ÙŠØªØ±ÙˆÙ†ÙŠØ¯Ø§Ø²ÙˆÙ„', 'Ù…ÙŠØªÙˆÙƒÙ„ÙˆØ¨Ø±Ø§Ù…ÙŠØ¯', 'Ù…ÙŠÙ…Ø§Ù†ØªÙŠÙ†', 'Ù†Ø§ØªØ§Ù…ÙŠØ³ÙŠÙ†', 'Ù†ÙŠØ§Ø³ÙŠÙ†Ø§Ù…ÙŠØ¯', 'Ù†ÙŠØ¨Ø§ÙÙŠÙ†Ø§Ùƒ', 'Ù†ÙŠØ³ØªØ§ØªÙŠÙ†', 'Ù‡ÙŠØ§Ù„ÙˆØ±ÙˆÙ†Ø§Øª Ø§Ù„ØµÙˆØ¯ÙŠÙˆÙ…', 'Ù‡ÙŠØ¯Ø±ÙˆÙƒØ³ÙŠØ²ÙŠÙ†', 'Ù‡ÙŠØ¯Ø±ÙˆÙƒÙˆØ±ØªÙŠØ²ÙˆÙ†', 'Ù‡ÙŠØ¯Ø±ÙˆÙƒÙŠÙ†ÙˆÙ†']\nEnglishWords=['Acetazolamide', 'Acetylcysteine', 'Albendazole', 'Amantadine', 'Amoxicillin', 'Artificial Tears', 'Atropine', 'Azithromycin', 'Bimatoprost', 'Botox', 'Brimonidine', 'Calcium Carbonate', 'Carbachol', 'Carbamazepine', 'Carbocisteine', 'Cefdinir', 'Cefixime', 'Cefuroxime', 'Cetirizine', 'Chloramphenicol', 'Chlorhexidine', 'Ciprofloxacin', 'Clindamycin', 'Collagen', 'Cyclosporine', 'Dexamethasone', 'Dextromethorphan', 'Diclofenac', 'Domperidone', 'Donepezil', 'Dorzolamide', 'Doxycycline', 'Erythromycin', 'Fluorometholone', 'Gabapentin', 'Gatifloxacin', 'Glycolic Acid', 'Guaifenesin', 'Hyaluronic Acid', 'Hydrocortisone', 'Hydroquinone', 'Hydroxyzine', 'Ibuprofen', 'Iron Supplements', 'Ketorolac', 'Lactic Acid', 'Latanoprost', 'Levetiracetam', 'Levofloxacin', 'Lidocaine', 'Lifitegrast', 'Loratadine', 'Mannitol', 'Mebendazole', 'Memantine', 'Metoclopramide', 'Metronidazole', 'Montelukast', 'Moxifloxacin', 'Multivitamins', 'Mupirocin', 'Natamycin', 'Nepafenac', 'Niacinamide', 'Nystatin', 'Ofloxacin', 'Omeprazole', 'Ondansetron', 'Oral Rehydration Salts', 'Paracetamol', 'Peptides', 'Pilocarpine', 'Pramipexole', 'Prednisolone', 'Prednisolone Acetate', 'Prednisolone Drops', 'Pregabalin', 'Probiotics', 'Ranitidine', 'Retinol', 'Rivastigmine', 'Ropinirole', 'Salbutamol', 'Salicylic Acid', 'Sodium Hyaluronate', 'Timolol', 'Tobramycin', 'Topiramate', 'Travoprost', 'Tretinoin', 'Tropicamide', 'Valproate', 'Vitamin C Serum', 'Vitamin D', 'Voriconazole', 'Zinc Sulfate''for', 'Every', 'After', 'Twice', 'needed', 'first', 'hours', 'breakfast', 'For', '8', 'awake', 'other', 'Night', 'hour', 'Morning', 'bed', '14', 'the', 'days', 'As', '5', 'bedtime', 'lunch', 'week', '7', 'daily', 'only', '4', 'Before', 'while', '3', 'minutes', '2', '6', 'day', '15', 'meals', 'Once', '12']\nfrequency_patterns = [\n    ## ğŸ”¹ English Frequencies\n    r\"\\bevery\\s\\d+\\shours?\\b\",            # \"every 6 hours\"\n    r\"\\bEvery\\shours\\b\",\n    r\"\\bevery\\s\\d+\\s?-\\s?\\d+\\shours?\\b\",  # \"every 4-6 hours\"\n    r\"\\bonce\\sdaily\\b\",                   # \"once daily\"\n    r\"\\btwice\\sdaily\\b\",                  # \"twice daily\"\n    r\"\\bthree\\stimes\\sa\\sday\\b\",          # \"three times a day\"\n    r\"\\bfour\\stimes\\sa\\sday\\b\",           # \"four times a day\"\n    r\"\\b\\d+\\stimes\\sa\\sday\\b\",            # \"5 times a day\"\n\n    ## â³ Time-Based\n    r\"\\bevery\\sother\\sday\\b\",             # \"every other day\"\n    r\"\\bevery\\s\\d+\\sdays?\\b\",             # \"every 3 days\"\n    r\"\\bevery\\s\\d+\\sweeks?\\b\",            # \"every 2 weeks\"\n    r\"\\bevery\\s\\d+\\smonths?\\b\",           # \"every 6 months\"\n\n    ## ğŸŒ™ Morning/Evening\n    r\"\\bin\\sthe\\smorning\\b\",              # \"in the morning\"\n    r\"\\bin\\sthe\\sevening\\b\",              # \"in the evening\"\n    r\"\\bin\\sthe\\safternoon\\b\",            # \"in the afternoon\"\n    r\"\\bin\\sthe\\snight\\b\",                # \"in the night\"\n    r\"\\bdaily\\sat\\snoon\\b\",               # \"daily at noon\"\n\n    ## ğŸ½ Meal-Based\n    r\"\\bbefore\\smeals?\\b\",                # \"before meals\"\n    r\"\\bbefore\\sbreakfast?\\b\",            # \"before breakfast\"\n    r\"\\bafter\\smeals?\\b\",                 # \"after meals\"\n    r\"\\bafter\\sbreakfast?\\b\",             # \"after breakfast\"\n    r\"\\bbefore\\sfood\\b\",                  # \"before food\"\n    r\"\\bafter\\sfood\\b\",                   # \"after food\"\n    r\"\\bon\\san\\sempty\\sstomach\\b\",        # \"on an empty stomach\"\n\n    ## ğŸŒ™ Sleep\n    r\"\\bbefore\\sbedtime\\b\",               # \"before bedtime\"\n    r\"\\bat\\sbedtime\\b\",                   # \"at bedtime\"\n    r\"\\bbefore\\sgoing\\sto\\sbed\\b\",        # \"before going to bed\"\n\n    ## ğŸ”„ PRN (As Needed)\n    r\"\\bas\\sneeded\\b\",                    # \"as needed\"\n    r\"\\bif\\sneeded\\b\",                    # \"if needed\"\n    r\"\\bwhen\\snecessary\\b\",               # \"when necessary\"\n    r\"\\bwhen\\srequired\\b\",                # \"when required\"\n    r\"\\bwhen\\sfeeling\\spain\\b\",           # \"when feeling pain\"\n\n    ## ğŸš‘ Perioperative\n    r\"\\bbefore\\ssurgery\\b\",               # \"before surgery\"\n    r\"\\bafter\\ssurgery\\b\",                # \"after surgery\"\n    r\"\\bbefore\\san\\soperation\\b\",         # \"before an operation\"\n    r\"\\bafter\\san\\soperation\\b\",          # \"after an operation\"\n\n    ## ğŸ”¹ Arabic Frequencies\n    r\"\\bÙƒÙ„\\s\\d+\\sØ³Ø§Ø¹Ø©\\b\",              # \"ÙƒÙ„ 8 Ø³Ø§Ø¹Ø§Øª\" (every X hours)\n    r\"\\bÙƒÙ„\\s\\d+\\s?-\\s?\\d+\\sØ³Ø§Ø¹Ø§Øª?\\b\",  # \"ÙƒÙ„ 4-6 Ø³Ø§Ø¹Ø§Øª\" (every X-Y hours)\n    r\"\\bÙ…Ø±Ø©\\sÙŠÙˆÙ…ÙŠØ§\\b\",                 # \"Ù…Ø±Ø© ÙŠÙˆÙ…ÙŠÙ‹Ø§\" (once daily)\n    r\"\\bÙ…Ø±Ø©\\sÙƒÙ„\\sÙŠÙˆÙ…\\b\",               # \"Ù…Ø±Ø© ÙƒÙ„ ÙŠÙˆÙ…\" (once per day)\n    r\"\\bÙ…Ø±Ø©\\sÙŠÙˆÙ…ÙŠØ§\\b\",                 # \"Ù…Ø±Ø© ÙŠÙˆÙ…ÙŠØ§\" (once per day)\n    r\"\\bÙ…Ø±Ø©\\sØ£Ø³Ø¨ÙˆØ¹ÙŠØ§\\b\",               # \"Ù…Ø±Ø© Ø£Ø³Ø¨ÙˆØ¹ÙŠÙ‹Ø§\" (once weekly)\n    r\"\\bÙ…Ø±Ø©\\sÙƒÙ„\\sØ£Ø³Ø¨ÙˆØ¹\\b\",             # \"Ù…Ø±Ø© ÙƒÙ„ Ø£Ø³Ø¨ÙˆØ¹\" (once per week)\n    r\"\\bÙ…Ø±Ø©\\sØ´Ù‡Ø±ÙŠØ§\\b\",                 # \"Ù…Ø±Ø© Ø´Ù‡Ø±ÙŠÙ‹Ø§\" (once monthly)\n    r\"\\bÙ…Ø±Ø©\\sÙƒÙ„\\sØ´Ù‡Ø±\\b\",               # \"Ù…Ø±Ø© ÙƒÙ„ Ø´Ù‡Ø±\" (once per month)\n    r\"\\bÙ…Ø±ØªÙŠÙ†\\sÙŠÙˆÙ…ÙŠØ§\\b\",               # \"Ù…Ø±ØªÙŠÙ† ÙŠÙˆÙ…ÙŠÙ‹Ø§\" (twice daily)\n    r\"\\b\\d+\\sÙ…Ø±Ø§Øª?\\sÙŠÙˆÙ…ÙŠØ§\\b\",          # \"3 Ù…Ø±Ø§Øª ÙŠÙˆÙ…ÙŠÙ‹Ø§\" (multiple times daily)\n\n    ## â³ Time-Based\n    r\"\\bÙƒÙ„\\sÙŠÙˆÙ…ÙŠÙ†\\b\",                   # \"ÙƒÙ„ ÙŠÙˆÙ…ÙŠÙ†\" (every other day)\n    r\"\\bÙƒÙ„\\s\\d+\\sØ£ÙŠØ§Ù…\\b\",               # \"ÙƒÙ„ 3 Ø£ÙŠØ§Ù…\" (every X days)\n    r\"\\bÙƒÙ„\\s\\d+\\sØ£Ø³Ø§Ø¨ÙŠØ¹\\b\",             # \"ÙƒÙ„ 2 Ø£Ø³Ø§Ø¨ÙŠØ¹\" (every X weeks)\n    r\"\\bÙƒÙ„\\s\\d+\\sØ´Ù‡ÙˆØ±\\b\",               # \"ÙƒÙ„ 6 Ø´Ù‡ÙˆØ±\" (every X months)\n\n   ## Arabic (Word-Based Numbers)\n    r\"\\bÙƒÙ„\\sØ³Ø§Ø¹Ø©\\b\",                     # \"ÙƒÙ„ ÙˆØ§Ø­Ø¯Ø© Ø³Ø§Ø¹Ø©\" (every one hour)\n    r\"\\bÙƒÙ„\\sØ³Ø§Ø¹ØªÙŠÙ†\\b\",                   # \"ÙƒÙ„ Ø§Ø«Ù†ØªÙŠÙ† Ø³Ø§Ø¹Ø©\" (every two hours)\n    r\"\\bÙƒÙ„\\sØ«Ù„Ø§Ø«\\sØ³Ø§Ø¹Ø§Øª\\b\",               # \"ÙƒÙ„ Ø«Ù„Ø§Ø« Ø³Ø§Ø¹Ø§Øª\" (every three hours)\n    r\"\\bÙƒÙ„\\sØ£Ø±Ø¨Ø¹\\sØ³Ø§Ø¹Ø§Øª\\b\",              # \"ÙƒÙ„ Ø£Ø±Ø¨Ø¹ Ø³Ø§Ø¹Ø§Øª\" (every four hours)\n    r\"\\bÙƒÙ„\\sØ®Ù…Ø³\\sØ³Ø§Ø¹Ø§Øª\\b\",               # \"ÙƒÙ„ Ø®Ù…Ø³ Ø³Ø§Ø¹Ø§Øª\" (every five hours)\n    r\"\\bÙƒÙ„\\sØ³Øª\\sØ³Ø§Ø¹Ø§Øª\\b\",                # \"ÙƒÙ„ Ø³Øª Ø³Ø§Ø¹Ø§Øª\" (every six hours)\n    r\"\\bÙƒÙ„\\sØ³Ø¨Ø¹\\sØ³Ø§Ø¹Ø§Øª\\b\",               # \"ÙƒÙ„ Ø³Ø¨Ø¹ Ø³Ø§Ø¹Ø§Øª\" (every seven hours)\n    r\"\\bÙƒÙ„\\sØ«Ù…Ø§Ù†ÙŠ\\sØ³Ø§Ø¹Ø§Øª\\b\",             # \"ÙƒÙ„ Ø«Ù…Ø§Ù†ÙŠ Ø³Ø§Ø¹Ø§Øª\" (every eight hours)\n    r\"\\bÙƒÙ„\\sØªØ³Ø¹\\sØ³Ø§Ø¹Ø§Øª\\b\",               # \"ÙƒÙ„ ØªØ³Ø¹ Ø³Ø§Ø¹Ø§Øª\" (every nine hours)\n    r\"\\bÙƒÙ„\\sØ¹Ø´Ø±\\sØ³Ø§Ø¹Ø§Øª\\b\",               # \"ÙƒÙ„ Ø¹Ø´Ø± Ø³Ø§Ø¹Ø§Øª\" (every ten hours)\n    r\"\\bÙƒÙ„\\sØ¥Ø­Ø¯Ù‰\\sØ¹Ø´Ø±Ø©\\sØ³Ø§Ø¹Ø©\\b\",         # \"ÙƒÙ„ Ø¥Ø­Ø¯Ù‰ Ø¹Ø´Ø±Ø© Ø³Ø§Ø¹Ø©\" (every 11 hours)\n    r\"\\bÙƒÙ„\\sØ§Ø«Ù†ØªÙŠ\\sØ¹Ø´Ø±Ø©\\sØ³Ø§Ø¹Ø©\\b\",        # \"ÙƒÙ„ Ø§Ø«Ù†ØªÙŠ Ø¹Ø´Ø±Ø© Ø³Ø§Ø¹Ø©\" (every 12 hours)\n\n    ## ğŸŒ™ Morning/Evening\n    r\"\\bÙÙŠ\\sØ§Ù„ØµØ¨Ø§Ø­\\b\",                  # \"ÙÙŠ Ø§Ù„ØµØ¨Ø§Ø­\" (in the morning)\n    r\"\\bÙÙŠ\\sØ§Ù„Ù…Ø³Ø§Ø¡\\b\",                  # \"ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø¡\" (in the evening)\n    r\"\\bÙÙŠ\\sØ§Ù„Ø¸Ù‡ÙŠØ±Ø©\\b\",                 # \"ÙÙŠ Ø§Ù„Ø¸Ù‡ÙŠØ±Ø©\" (at noon)\n    r\"\\bÙÙŠ\\sØ§Ù„Ù„ÙŠÙ„\\b\",                   # \"ÙÙŠ Ø§Ù„Ù„ÙŠÙ„\" (at night)\n\n    ## ğŸ½ Meal-Based\n    r\"\\bÙ‚Ø¨Ù„\\sØ§Ù„Ø£ÙƒÙ„\\b\",                  # \"Ù‚Ø¨Ù„ Ø§Ù„Ø£ÙƒÙ„\" (before meals)\n    r\"\\bØ¨Ø¹Ø¯\\sØ§Ù„Ø£ÙƒÙ„\\b\",                  # \"Ø¨Ø¹Ø¯ Ø§Ù„Ø£ÙƒÙ„\" (after meals)\n    r\"\\bÙ‚Ø¨Ù„\\sØ§Ù„Ø·Ø¹Ø§Ù…\\b\",                 # \"Ù‚Ø¨Ù„ Ø§Ù„Ø·Ø¹Ø§Ù…\" (before food)\n    r\"\\bØ¨Ø¹Ø¯\\sØ§Ù„Ø·Ø¹Ø§Ù…\\b\",                 # \"Ø¨Ø¹Ø¯ Ø§Ù„Ø·Ø¹Ø§Ù…\" (after food)\n    r\"\\bØ¹Ù„Ù‰\\sÙ…Ø¹Ø¯Ø©\\sÙØ§Ø±ØºØ©\\b\",            # \"Ø¹Ù„Ù‰ Ù…Ø¹Ø¯Ø© ÙØ§Ø±ØºØ©\" (on an empty stomach)\n    r\"\\bØ¹Ù„Ù‰\\sØ§Ù„Ø±ÙŠÙ‚\\b\",                   # \"Ø¹Ù„Ù‰ Ø§Ù„Ø±ÙŠÙ‚\" (fasting)\n\n    ## ğŸŒ™ Sleep\n    r\"\\bÙ‚Ø¨Ù„\\sØ§Ù„Ù†ÙˆÙ…\\b\",                 # \"Ù‚Ø¨Ù„ Ø§Ù„Ù†ÙˆÙ…\" (before sleep)\n    r\"\\bØ¹Ù†Ø¯\\sØ§Ù„Ù†ÙˆÙ…\\b\",                 # \"Ø¹Ù†Ø¯ Ø§Ù„Ù†ÙˆÙ…\" (at bedtime)\n\n    ## ğŸ”„ PRN (As Needed)\n    r\"\\bØ¹Ù†Ø¯\\sØ§Ù„Ù„Ø²ÙˆÙ…\\b\",                # \"Ø¹Ù†Ø¯ Ø§Ù„Ù„Ø²ÙˆÙ…\" (as needed)\n    r\"\\bØ­Ø³Ø¨\\sØ§Ù„Ø­Ø§Ø¬Ø©\\b\",                # \"Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø©\" (as required)\n    r\"\\bØ¥Ø°Ø§\\sØ§Ø³ØªØ¯Ø¹Øª\\sØ§Ù„Ø­Ø§Ø¬Ø©\\b\",         # \"Ø¥Ø°Ø§ Ø§Ø³ØªØ¯Ø¹Øª Ø§Ù„Ø­Ø§Ø¬Ø©\" (if necessary)\n    r\"\\bØ¹Ù†Ø¯\\sØ§Ù„Ø´Ø¹ÙˆØ±\\sØ¨Ø§Ù„Ø£Ù„Ù…\\b\",          # \"Ø¹Ù†Ø¯ Ø§Ù„Ø´Ø¹ÙˆØ± Ø¨Ø§Ù„Ø£Ù„Ù…\" (when feeling pain)\n\n    ## ğŸš‘ Perioperative\n    r\"\\bÙ‚Ø¨Ù„\\sØ§Ù„Ø¹Ù…Ù„ÙŠØ©\\b\",              # \"Ù‚Ø¨Ù„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©\" (before surgery)\n    r\"\\bØ¨Ø¹Ø¯\\sØ§Ù„Ø¹Ù…Ù„ÙŠØ©\\b\",              # \"Ø¨Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©\" (after surgery)\n    r\"\\bÙ‚Ø¨Ù„\\sØ§Ù„ØªØ¯Ø®Ù„\\sØ§Ù„Ø¬Ø±Ø§Ø­ÙŠ\\b\",     # \"Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø®Ù„ Ø§Ù„Ø¬Ø±Ø§Ø­ÙŠ\" (before an operation)\n    r\"\\bØ¨Ø¹Ø¯\\sØ§Ù„ØªØ¯Ø®Ù„\\sØ§Ù„Ø¬Ø±Ø§Ø­ÙŠ\\b\",     # \"Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø®Ù„ Ø§Ù„Ø¬Ø±Ø§Ø­ÙŠ\" (after an operation)\n    r\"\\bEvery\\s\\d+\\shours?\\b\",            # \"Every 8 hours\" (capitalized)\n    r\"\\bEvery\\shours?\\b\",                 # \"Every hours\" (capitalized)\n    r\"\\bAfter\\slunch\\b\",                  # \"After lunch\" (capitalized)\n    r\"\\bOnce\\sdaily\\b\",                   # \"Once daily\" (capitalized)\n\n]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T17:56:29.923580Z","iopub.execute_input":"2025-04-16T17:56:29.923872Z","iopub.status.idle":"2025-04-16T17:58:23.945284Z","shell.execute_reply.started":"2025-04-16T17:56:29.923850Z","shell.execute_reply":"2025-04-16T17:58:23.944312Z"}},"outputs":[{"name":"stdout","text":"Collecting jiwer\n  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\nCollecting rapidfuzz>=3.9.7 (from jiwer)\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\nDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\nSuccessfully installed jiwer-3.1.0 rapidfuzz-3.13.0\nCollecting ultralytics\n  Downloading ultralytics-8.3.109-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.109-py3-none-any.whl (974 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m974.8/974.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.109 ultralytics-thop-2.0.14\nRequirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n","output_type":"stream"},{"name":"stderr","text":"2025-04-16 17:58:08.882424: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744826289.132199      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744826289.210441      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"MODEL_NAME = \"microsoft/trocr-base-handwritten\"\nprocessor = TrOCRProcessor.from_pretrained(MODEL_NAME) # Initialize the processor here\nnew_model = VisionEncoderDecoderModel.from_pretrained(MODEL_NAME)\nnew_model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\nnew_model.config.pad_token_id = processor.tokenizer.pad_token_id\nnew_model.load_state_dict(torch.load(\"/kaggle/input/trocr_finetune_weights_stp/pytorch/default/1/model_weights.pth\"))\nDEFAULT_FREQUENCY = \"Every 6 hours\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T17:58:23.946848Z","iopub.execute_input":"2025-04-16T17:58:23.947376Z","iopub.status.idle":"2025-04-16T17:58:46.616844Z","shell.execute_reply.started":"2025-04-16T17:58:23.947356Z","shell.execute_reply":"2025-04-16T17:58:46.615960Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/224 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ae236fc90b54d99a39fdeb7c369ead3"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b24c2b6fcbf48009366d4edf39091da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d89d3e5c484c4a618e01e85b5eba6f8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1064272362764a28a4856699d6f5b2f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83e9ddadd91e4a5fa1da87dd39e80215"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cf0964101224ebe9abcaa699f29087e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f266ed650d0d42ff8b486abd0c73b7c5"}},"metadata":{}},{"name":"stderr","text":"Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n  \"attention_probs_dropout_prob\": 0.0,\n  \"encoder_stride\": 16,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 768,\n  \"image_size\": 384,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"model_type\": \"vit\",\n  \"num_attention_heads\": 12,\n  \"num_channels\": 3,\n  \"num_hidden_layers\": 12,\n  \"patch_size\": 16,\n  \"pooler_act\": \"tanh\",\n  \"pooler_output_size\": 768,\n  \"qkv_bias\": false,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.51.1\"\n}\n\nConfig of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_cross_attention\": true,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": 0.0,\n  \"cross_attention_hidden_size\": 768,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 12,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"eos_token_id\": 2,\n  \"init_std\": 0.02,\n  \"is_decoder\": true,\n  \"layernorm_embedding\": true,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"trocr\",\n  \"pad_token_id\": 1,\n  \"scale_embedding\": false,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.51.1\",\n  \"use_cache\": false,\n  \"use_learned_position_embeddings\": true,\n  \"vocab_size\": 50265\n}\n\nSome weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c5810eab74c48babbd46917a2b5fc9f"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from sklearn.cluster import DBSCAN\n\ndef preprocess_for_trocr(cropped_image):\n    # Convert BGR (OpenCV) to RGB (PIL)\n    rgb_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n    pil_image = Image.fromarray(rgb_image)\n    return pil_image\n\ndef fuzzy_match(word, word_list, threshold=30):\n    result = process.extractOne(word, word_list, scorer=fuzz.ratio)\n    if result:\n        # Handle different versions of fuzzywuzzy\n        if isinstance(result, tuple) and len(result) >= 2:\n            match, score = result[0], result[1]  # Extract match and score\n            return match if score >= threshold else None\n    return None\n\ndef remove_duplicate_boxes(boxes, iou_threshold=0.8):\n    if len(boxes) == 0:\n        return []\n\n    # Convert boxes to (x1, y1, x2, y2) format\n    boxes = np.array(boxes)\n    x1 = boxes[:, 0]\n    y1 = boxes[:, 1]\n    x2 = boxes[:, 2]\n    y2 = boxes[:, 3]\n    # Compute the area of the bounding boxes\n    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n\n    # Sort the boxes by the bottom-right y-coordinate\n    indices = np.argsort(y2)\n    keep = []\n\n    while len(indices) > 0:\n        last = len(indices) - 1\n        i = indices[last]\n        keep.append(i)\n\n        # Compute the IoU of the remaining boxes with the last box\n        xx1 = np.maximum(x1[i], x1[indices[:last]])\n        yy1 = np.maximum(y1[i], y1[indices[:last]])\n        xx2 = np.minimum(x2[i], x2[indices[:last]])\n        yy2 = np.minimum(y2[i], y2[indices[:last]])\n\n        w = np.maximum(0, xx2 - xx1 + 1)\n        h = np.maximum(0, yy2 - yy1 + 1)\n        overlap = (w * h) / areas[indices[:last]]\n\n        # Remove boxes with IoU greater than the threshold\n        indices = np.delete(indices, np.concatenate(([last], np.where(overlap > iou_threshold)[0])))\n\n    return boxes[keep].tolist()\n\ndef group_boxes_into_lines_and_sort(boxes, texts, vertical_threshold=20):\n    if not boxes or not texts:\n        return [], []\n    \n    # Convert boxes to include center points and other useful metrics\n    box_data = []\n    for i, (box, text) in enumerate(zip(boxes, texts)):\n        if text:  # Only process boxes with valid text\n            x1, y1, x2, y2 = box\n            center_y = (y1 + y2) / 2\n            center_x = (x1 + x2) / 2\n            height = y2 - y1\n            box_data.append({\n                'index': i,\n                'box': box,\n                'text': text,\n                'center_x': center_x,\n                'center_y': center_y,\n                'height': height\n            })\n    \n    if not box_data:\n        return [], []\n    \n    # Dynamically adjust vertical threshold based on average text height\n    avg_height = sum(item['height'] for item in box_data) / len(box_data)\n    dynamic_threshold = max(vertical_threshold, avg_height * 0.7)\n    \n    # Initial sort by y-coordinate\n    box_data.sort(key=lambda x: x['center_y'])\n    \n    # Use DBSCAN clustering to group lines\n    points = np.array([[item['center_x'], item['center_y']] for item in box_data])\n    # Adjust eps based on average height\n    clustering = DBSCAN(eps=dynamic_threshold, min_samples=1).fit(points)\n    labels = clustering.labels_\n    \n    # Group boxes by cluster label\n    lines = {}\n    for i, label in enumerate(labels):\n        if label not in lines:\n            lines[label] = []\n        lines[label].append(box_data[i])\n    \n    # Sort lines by average y-coordinate\n    sorted_lines = sorted(lines.values(), key=lambda line: sum(item['center_y'] for item in line)/len(line))\n    \n    # Sort each line by x-coordinate (left to right)\n    for line in sorted_lines:\n        line.sort(key=lambda x: x['center_x'])\n    \n    # Extract the ordered text and boxes\n    ordered_text = []\n    ordered_boxes = []\n    for line in sorted_lines:\n        for box in line:\n            ordered_text.append(box['text'])\n            ordered_boxes.append(box['box'])\n    \n    return ordered_text, ordered_boxes\n\ndef TextExtraction(images):\n    extracted_data = []\n    for image_path in images:\n        image = cv2.imread(image_path)\n        image_data = {\n            \"image_path\": image_path,\n            \"text\": \"\",  # Full text in reading order\n            \"words\": []  # List to store {text, position} for each word\n        }\n        \n        # Run YOLOv8 detection\n        results = model(image)\n        boxes = results[0].boxes.xyxy.cpu().numpy()\n        class_ids = results[0].boxes.cls.cpu().numpy()\n        \n        # Remove duplicate boxes\n        boxes = remove_duplicate_boxes(boxes)\n        \n        # Extract text from each box\n        all_texts = []\n        for i, box in enumerate(boxes):\n            x1, y1, x2, y2 = map(int, box)\n            cropped_image = image[y1:y2, x1:x2]\n            \n            # Preprocess for TrOCR\n            trocr_input = preprocess_for_trocr(cropped_image)\n            inputs = processor(images=trocr_input, return_tensors=\"pt\").to(new_model.device)\n            \n            # Extract text\n            with torch.no_grad():\n                generated_ids = new_model.generate(**inputs)\n                output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n            \n            # Fuzzy match with language-specific dictionary\n            class_id = int(class_ids[i])\n            word_list = ArabicWords if class_id == 0 else EnglishWords\n            matched_text = fuzzy_match(output_text.strip(), word_list)\n            if matched_text:\n                all_texts.append(matched_text)\n                # Save the original box for later\n                boxes[i] = box  # Ensure box is in the right format\n        \n        # Group into lines and sort in reading order\n        ordered_texts, ordered_boxes = group_boxes_into_lines_and_sort(boxes, all_texts)\n        \n        # Build the complete text and word objects\n        full_text = \" \".join(ordered_texts)\n        image_data[\"text\"] = full_text\n        \n        for text, box in zip(ordered_texts, ordered_boxes):\n            x1, y1, x2, y2 = map(int, box)\n            image_data[\"words\"].append({\n                \"text\": text,\n                \"position\": (x1, y1, x2, y2)\n            })\n        \n        extracted_data.append(image_data)\n    \n    return extracted_data\n\ndef sort_words_by_position(word_data):\n    # Sort by y1 (top-to-bottom), then by x1 (left-to-right)\n    return sorted(word_data, key=lambda x: (x[\"position\"][1], x[\"position\"][0]))\n\ndef print_sorted_words(sorted_words):\n    print(\"Sorted Words (Top-to-Bottom, Left-to-Right):\")\n    for i, word in enumerate(sorted_words):\n        print(f\"{i+1}: '{word['text']}' at {word['position']}\")\n\ndef organize_medication_instructions(words_with_coords):\n    # Step 1: Calculate the center y-coordinate for each word's bounding box\n    words_with_y_center = []\n    for word_dict in words_with_coords:\n        word = word_dict['text']\n        coords = word_dict['position']  # Assuming this is (x1, y1, x2, y2)\n        x1, y1, x2, y2 = coords\n        y_center = (y1 + y2) / 2\n        x_center = (x1 + x2) / 2\n        words_with_y_center.append((word, y_center, x_center, coords))\n    \n    # Step 2: Sort words by their y-coordinate (top to bottom)\n    words_with_y_center.sort(key=lambda x: x[1])\n    \n    # Step 3: Group words that are likely on the same line\n    # We'll consider words to be on the same line if their y-centers are within a threshold\n    y_threshold = 100  # This can be adjusted based on your document's layout\n    \n    lines = []\n    current_line = [words_with_y_center[0]]\n    \n    for i in range(1, len(words_with_y_center)):\n        current_word = words_with_y_center[i]\n        previous_word = words_with_y_center[i-1]\n        \n        # If this word is close in y-position to the previous word, add it to the current line\n        if abs(current_word[1] - previous_word[1]) < y_threshold:\n            current_line.append(current_word)\n        # Otherwise, start a new line\n        else:\n            lines.append(current_line)\n            current_line = [current_word]\n    \n    # Add the last line if it's not empty\n    if current_line:\n        lines.append(current_line)\n    \n    # Step 4: Sort words within each line by x-coordinate (left to right)\n    for i in range(len(lines)):\n        lines[i].sort(key=lambda x: x[2])  # Sort by x_center\n    \n    # Step 5: Join words in each line to form complete instructions\n    instructions = []\n    for line in lines:\n        instruction = \" \".join(word[0] for word in line)\n        instructions.append(instruction)\n    \n    return instructions\n\ndef create_medication_frequency_pairs(organized_instructions):\n    # Step 1: Concatenate all instructions into one line\n    all_text = \" \".join(organized_instructions)\n    \n    \n    # Step 3: Extract medication-frequency pairs\n    medication_pairs = []\n    \n    # Simple approach: Find a medication and assume text until the next medication is its frequency\n    for i, med in enumerate(medicine_list):\n        match = re.search(r'\\b' + med + r'\\b', all_text, re.IGNORECASE)\n        if match:\n            start_idx = match.start()\n            \n            # Find the next medication in the text after this one\n            next_med_idx = float('inf')\n            for other_med in medicine_list:\n                if other_med != med:\n                    other_match = re.search(r'\\b' + other_med + r'\\b', all_text[start_idx+len(med):], re.IGNORECASE)\n                    if other_match:\n                        if start_idx + len(med) + other_match.start() < next_med_idx:\n                            next_med_idx = start_idx + len(med) + other_match.start()\n            \n            # Extract the frequency instruction\n            if next_med_idx != float('inf'):\n                frequency = all_text[start_idx+len(med):next_med_idx].strip()\n            else:\n                frequency = all_text[start_idx+len(med):].strip()\n            \n            medication_pairs.append((med, frequency))\n    \n    # Step 4: More sophisticated approach using patterns specific to medication instructions\n    if not medication_pairs:\n        # Pattern: Look for medication name followed by frequency info\n        patterns = [\n            # Medication followed by \"Every X hours\"\n            (r'(\\b\\w+\\b)\\s+Every\\s+(\\d+)\\s+hours', lambda m: (m.group(1), f\"Every {m.group(2)} hours\")),\n            \n            # Medication followed by \"Once daily\"\n            (r'(\\b\\w+\\b)\\s+Once\\s+daily', lambda m: (m.group(1), \"Once daily\")),\n            \n            # Medication followed by \"After lunch\"\n            (r'(\\b\\w+\\b)\\s+After\\s+lunch', lambda m: (m.group(1), \"After lunch\")),\n            \n            # More patterns can be added for different frequency formats\n        ]\n        \n        for pattern, extract_func in patterns:\n            for match in re.finditer(pattern, all_text, re.IGNORECASE):\n                medication_pairs.append(extract_func(match))\n    \n    return medication_pairs\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T18:04:42.857594Z","iopub.execute_input":"2025-04-16T18:04:42.858341Z","iopub.status.idle":"2025-04-16T18:04:43.276252Z","shell.execute_reply.started":"2025-04-16T18:04:42.858313Z","shell.execute_reply":"2025-04-16T18:04:43.275401Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def submit(images):\n    results = [] \n    extracted_data = TextExtraction(images)\n\n    for prescription_data in extracted_data:\n        sorted_words = sort_words_by_position(prescription_data[\"words\"])\n        print(f\"\\nSorted words for {prescription_data['image_path']}:\")\n        print_sorted_words(sorted_words)\n        print(\"-------------------------------------------------------------------------------\")\n        organized_instructions = organize_medication_instructions(sorted_words)\n\n        print(\"Organized Medication Instructions:\")\n        for i, instruction in enumerate(organized_instructions, 1):\n            print(f\"{i}. {instruction}\")\n        print(\"-------------------------------------------------------------------------------\")\n        medication_pairs = create_medication_frequency_pairs(organized_instructions)\n\n        print(\"\\nMedication-Frequency Pairs:\")\n        for med, freq in medication_pairs:\n            print(f\"- {med}: {freq}\")\n        results.append({\n            \"image_path\": prescription_data[\"image_path\"],\n            \"prescription_pairs\": medication_pairs\n        })\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T18:05:41.970036Z","iopub.execute_input":"2025-04-16T18:05:41.970381Z","iopub.status.idle":"2025-04-16T18:05:41.975915Z","shell.execute_reply.started":"2025-04-16T18:05:41.970359Z","shell.execute_reply":"2025-04-16T18:05:41.975251Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Example list of image file paths (update with actual paths)\nimages = ['/kaggle/input/machathon6-phase1-images/Beauty_prescription_104.jpg','/kaggle/input/machathon6-phase1-images/Beauty_prescription_116.jpg','/kaggle/input/machathon6-phase1-images/Dental_prescription_591.jpg', '/kaggle/input/machathon6-phase1-images/Neurology_prescription_131.jpg']\n\n# Call the submit function\nresults = submit(images)\n\n# Print the structured results\nfor i, result in enumerate(results):\n    print(f\"\\nPrescription {i + 1} ({result['image_path']}):\")\n    if not result[\"prescription_pairs\"]:\n        print(\"  No medicine-frequency pairs found\")\n    else:\n        for medicine, frequency in result[\"prescription_pairs\"]:\n            print(f\"  Medicine: {medicine}, Frequency: {frequency}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}