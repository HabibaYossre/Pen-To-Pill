{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content of each cell\n",
    "pd.set_option('display.expand_frame_repr', False)  # Avoid line wrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# medicine list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicine_list = [\n",
    "    # English Medicines\n",
    "    \"Cyclosporine\", \"Mebendazole\", \"Pilocarpine\", \"Calcium\", \"Hydrocortisone\", \"Memantine\",\n",
    "    \"Hydroquinone\", \"Loratadine\", \"Guaifenesin\", \"Retinol\", \"Hydroxyzine\", \"Carbocisteine\",\n",
    "    \"Montelukast\", \"Dexamethasone\", \"Niacinamide\", \"Cefdinir\", \"Albendazole\", \"Gabapentin\",\n",
    "    \"Levetiracetam\", \"Zinc\", \"Chlorhexidine\", \"Diclofenac\", \"Prednisolone\", \"Botox\",\n",
    "    \"Dextromethorphan\", \"Lidocaine\", \"Metronidazole\", \"Acetylcysteine\", \"Ciprofloxacin\",\n",
    "    \"Clindamycin\", \"Probiotics\", \"Erythromycin\", \"Paracetamol\", \"Omeprazole\",\n",
    "    \"Fluorometholone\", \"Azithromycin\", \"Nystatin\", \"Valproate\", \"Pramipexole\",\n",
    "    \"Carbamazepine\", \"Tretinoin\", \"Ofloxacin\", \"Tobramycin\", \"Timolol\", \"Ropinirole\",\n",
    "    \"Brimonidine\", \"Pregabalin\", \"Rivastigmine\", \"Amantadine\", \"Ranitidine\",\n",
    "    \"Salbutamol\", \"Domperidone\", \"Vitamin\", \"Dorzolamide\", \"Cetirizine\", \"Cefixime\",\n",
    "    \"Topiramate\", \"Iron\", \"Latanoprost\", \"Multivitamins\", \"Donepezil\", \"Hyaluronic\",\n",
    "    \"Ibuprofen\", \"Ondansetron\", \"Mupirocin\", \"Amoxicillin\", \"Doxycycline\",\"Carbachol\", \n",
    "    \"Oral Amoxicillin\",\n",
    "    \n",
    "    # Arabic Medicines\n",
    "    \"حمض الجليكوليك\", \"حمض الساليسيليك\", \"الببتيدات\",\n",
    "    \"أملاح\", \"إريثرومايسين\", \"باراسيتامول\", \"دوكسيسيكلين\", \"ميبيندازول\",\n",
    "    \"الزنك\", \"كاربوسيستين\", \"رانيتيدين\", \"أوندانسيترون\", \"مونتيلوكاست\",\n",
    "    \"كلورهيكسيدين\", \"ديكلوفيناك\", \"ليدوكايين\", \"بريجابالين\", \"أزيثروميسين\",\n",
    "    \"فيتامين\", \"نياسيناميد\", \"غوايفينيسين\", \"فالبروات\", \"أموكسيسيلين\",\n",
    "    \"هيدروكسيزين\", \"البوتوكس\", \"لاتانوبروست\", \"توبراميسين\", \"جابابنتين\",\n",
    "    \"ديكساميثازون\", \"ديكستروميثورفان\", \"سيبروفلوكساسين\", \"ليفيتيراسيتام\",\n",
    "    \"الكالسيوم\", \"تيمولول\", \"روبينيرول\", \"الهيالورونيك\", \"كاربامازيبين\",\n",
    "    \"نيستاتين\", \"إيبوبروفين\", \"بريمونيدين\", \"ألبيندازول\", \"هيدروكورتيزون\",\n",
    "    \"ريفاستجمين\", \"موبيروسين\", \"كليندامايسين\", \"أسيتيل\", \"هيدروكينون\",\n",
    "    \"البروبيوتيك\", \"ميترونيدازول\", \"دونيبيزيل\", \"أمانتادين\", \"بيلوكاربين\",\n",
    "    \"سيكلوسبورين\", \"تريتينوين\", \"ريتينول\", \"الحديد\", \"أوفلوكساسين\",\n",
    "    \"فلوروميثولون\", \"بريدنيزولون\", \"سيفيكسيم\", \"سيفدينير\", \"كربونات\", \"كارباشول\", \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# frequency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_patterns = [\n",
    "    ## 🔹 English Frequencies\n",
    "    r\"\\bevery\\s\\d+\\shours?\\b\",            # \"every 6 hours\"\n",
    "    r\"\\bEvery\\shours\\b\",\n",
    "    r\"\\bevery\\s\\d+\\s?-\\s?\\d+\\shours?\\b\",  # \"every 4-6 hours\"\n",
    "    r\"\\bonce\\sdaily\\b\",                   # \"once daily\"\n",
    "    r\"\\btwice\\sdaily\\b\",                  # \"twice daily\"\n",
    "    r\"\\bthree\\stimes\\sa\\sday\\b\",          # \"three times a day\"\n",
    "    r\"\\bfour\\stimes\\sa\\sday\\b\",           # \"four times a day\"\n",
    "    r\"\\b\\d+\\stimes\\sa\\sday\\b\",            # \"5 times a day\"\n",
    "    \n",
    "    ## ⏳ Time-Based\n",
    "    r\"\\bevery\\sother\\sday\\b\",             # \"every other day\"\n",
    "    r\"\\bevery\\s\\d+\\sdays?\\b\",             # \"every 3 days\"\n",
    "    r\"\\bevery\\s\\d+\\sweeks?\\b\",            # \"every 2 weeks\"\n",
    "    r\"\\bevery\\s\\d+\\smonths?\\b\",           # \"every 6 months\"\n",
    "    \n",
    "    ## 🌙 Morning/Evening\n",
    "    r\"\\bin\\sthe\\smorning\\b\",              # \"in the morning\"\n",
    "    r\"\\bin\\sthe\\sevening\\b\",              # \"in the evening\"\n",
    "    r\"\\bin\\sthe\\safternoon\\b\",            # \"in the afternoon\"\n",
    "    r\"\\bin\\sthe\\snight\\b\",                # \"in the night\"\n",
    "    r\"\\bdaily\\sat\\snoon\\b\",               # \"daily at noon\"\n",
    "    \n",
    "    ## 🍽 Meal-Based\n",
    "    r\"\\bbefore\\smeals?\\b\",                # \"before meals\"\n",
    "    r\"\\bbefore\\sbreakfast?\\b\",            # \"before breakfast\"\n",
    "    r\"\\bafter\\smeals?\\b\",                 # \"after meals\"\n",
    "    r\"\\bafter\\sbreakfast?\\b\",             # \"after breakfast\"\n",
    "    r\"\\bbefore\\sfood\\b\",                  # \"before food\"\n",
    "    r\"\\bafter\\sfood\\b\",                   # \"after food\"\n",
    "    r\"\\bon\\san\\sempty\\sstomach\\b\",        # \"on an empty stomach\"\n",
    "    \n",
    "    ## 🌙 Sleep\n",
    "    r\"\\bbefore\\sbedtime\\b\",               # \"before bedtime\"\n",
    "    r\"\\bat\\sbedtime\\b\",                   # \"at bedtime\"\n",
    "    r\"\\bbefore\\sgoing\\sto\\sbed\\b\",        # \"before going to bed\"\n",
    "    \n",
    "    ## 🔄 PRN (As Needed)\n",
    "    r\"\\bas\\sneeded\\b\",                    # \"as needed\"\n",
    "    r\"\\bif\\sneeded\\b\",                    # \"if needed\"\n",
    "    r\"\\bwhen\\snecessary\\b\",               # \"when necessary\"\n",
    "    r\"\\bwhen\\srequired\\b\",                # \"when required\"\n",
    "    r\"\\bwhen\\sfeeling\\spain\\b\",           # \"when feeling pain\"\n",
    "    \n",
    "    ## 🚑 Perioperative\n",
    "    r\"\\bbefore\\ssurgery\\b\",               # \"before surgery\"\n",
    "    r\"\\bafter\\ssurgery\\b\",                # \"after surgery\"\n",
    "    r\"\\bbefore\\san\\soperation\\b\",         # \"before an operation\"\n",
    "    r\"\\bafter\\san\\soperation\\b\",          # \"after an operation\"\n",
    "\n",
    "    ## 🔹 Arabic Frequencies\n",
    "    r\"\\bكل\\s\\d+\\sساعة\\b\",              # \"كل 8 ساعات\" (every X hours)\n",
    "    r\"\\bكل\\s\\d+\\s?-\\s?\\d+\\sساعات?\\b\",  # \"كل 4-6 ساعات\" (every X-Y hours)\n",
    "    r\"\\bمرة\\sيوميا\\b\",                 # \"مرة يوميًا\" (once daily)\n",
    "    r\"\\bمرة\\sكل\\sيوم\\b\",               # \"مرة كل يوم\" (once per day)\n",
    "    r\"\\bمرة\\sيوميا\\b\",                 # \"مرة يوميا\" (once per day)\n",
    "    r\"\\bمرة\\sأسبوعيا\\b\",               # \"مرة أسبوعيًا\" (once weekly)\n",
    "    r\"\\bمرة\\sكل\\sأسبوع\\b\",             # \"مرة كل أسبوع\" (once per week)\n",
    "    r\"\\bمرة\\sشهريا\\b\",                 # \"مرة شهريًا\" (once monthly)\n",
    "    r\"\\bمرة\\sكل\\sشهر\\b\",               # \"مرة كل شهر\" (once per month)\n",
    "    r\"\\bمرتين\\sيوميا\\b\",               # \"مرتين يوميًا\" (twice daily)\n",
    "    r\"\\b\\d+\\sمرات?\\sيوميا\\b\",          # \"3 مرات يوميًا\" (multiple times daily)\n",
    "    \n",
    "    ## ⏳ Time-Based\n",
    "    r\"\\bكل\\sيومين\\b\",                   # \"كل يومين\" (every other day)\n",
    "    r\"\\bكل\\s\\d+\\sأيام\\b\",               # \"كل 3 أيام\" (every X days)\n",
    "    r\"\\bكل\\s\\d+\\sأسابيع\\b\",             # \"كل 2 أسابيع\" (every X weeks)\n",
    "    r\"\\bكل\\s\\d+\\sشهور\\b\",               # \"كل 6 شهور\" (every X months)\n",
    "\n",
    "   ## Arabic (Word-Based Numbers)\n",
    "    r\"\\bكل\\sساعة\\b\",                     # \"كل واحدة ساعة\" (every one hour)\n",
    "    r\"\\bكل\\sساعتين\\b\",                   # \"كل اثنتين ساعة\" (every two hours)\n",
    "    r\"\\bكل\\sثلاث\\sساعات\\b\",               # \"كل ثلاث ساعات\" (every three hours)\n",
    "    r\"\\bكل\\sأربع\\sساعات\\b\",              # \"كل أربع ساعات\" (every four hours)\n",
    "    r\"\\bكل\\sخمس\\sساعات\\b\",               # \"كل خمس ساعات\" (every five hours)\n",
    "    r\"\\bكل\\sست\\sساعات\\b\",                # \"كل ست ساعات\" (every six hours)\n",
    "    r\"\\bكل\\sسبع\\sساعات\\b\",               # \"كل سبع ساعات\" (every seven hours)\n",
    "    r\"\\bكل\\sثماني\\sساعات\\b\",             # \"كل ثماني ساعات\" (every eight hours)\n",
    "    r\"\\bكل\\sتسع\\sساعات\\b\",               # \"كل تسع ساعات\" (every nine hours)\n",
    "    r\"\\bكل\\sعشر\\sساعات\\b\",               # \"كل عشر ساعات\" (every ten hours)\n",
    "    r\"\\bكل\\sإحدى\\sعشرة\\sساعة\\b\",         # \"كل إحدى عشرة ساعة\" (every 11 hours)\n",
    "    r\"\\bكل\\sاثنتي\\sعشرة\\sساعة\\b\",        # \"كل اثنتي عشرة ساعة\" (every 12 hours)\n",
    "    \n",
    "    ## 🌙 Morning/Evening\n",
    "    r\"\\bفي\\sالصباح\\b\",                  # \"في الصباح\" (in the morning)\n",
    "    r\"\\bفي\\sالمساء\\b\",                  # \"في المساء\" (in the evening)\n",
    "    r\"\\bفي\\sالظهيرة\\b\",                 # \"في الظهيرة\" (at noon)\n",
    "    r\"\\bفي\\sالليل\\b\",                   # \"في الليل\" (at night)\n",
    "    \n",
    "    ## 🍽 Meal-Based\n",
    "    r\"\\bقبل\\sالأكل\\b\",                  # \"قبل الأكل\" (before meals)\n",
    "    r\"\\bبعد\\sالأكل\\b\",                  # \"بعد الأكل\" (after meals)\n",
    "    r\"\\bقبل\\sالطعام\\b\",                 # \"قبل الطعام\" (before food)\n",
    "    r\"\\bبعد\\sالطعام\\b\",                 # \"بعد الطعام\" (after food)\n",
    "    r\"\\bعلى\\sمعدة\\sفارغة\\b\",            # \"على معدة فارغة\" (on an empty stomach)\n",
    "    r\"\\bعلى\\sالريق\\b\",                   # \"على الريق\" (fasting)\n",
    "    \n",
    "    ## 🌙 Sleep\n",
    "    r\"\\bقبل\\sالنوم\\b\",                 # \"قبل النوم\" (before sleep)\n",
    "    r\"\\bعند\\sالنوم\\b\",                 # \"عند النوم\" (at bedtime)\n",
    "    \n",
    "    ## 🔄 PRN (As Needed)\n",
    "    r\"\\bعند\\sاللزوم\\b\",                # \"عند اللزوم\" (as needed)\n",
    "    r\"\\bحسب\\sالحاجة\\b\",                # \"حسب الحاجة\" (as required)\n",
    "    r\"\\bإذا\\sاستدعت\\sالحاجة\\b\",         # \"إذا استدعت الحاجة\" (if necessary)\n",
    "    r\"\\bعند\\sالشعور\\sبالألم\\b\",          # \"عند الشعور بالألم\" (when feeling pain)\n",
    "    \n",
    "    ## 🚑 Perioperative\n",
    "    r\"\\bقبل\\sالعملية\\b\",              # \"قبل العملية\" (before surgery)\n",
    "    r\"\\bبعد\\sالعملية\\b\",              # \"بعد العملية\" (after surgery)\n",
    "    r\"\\bقبل\\sالتدخل\\sالجراحي\\b\",     # \"قبل التدخل الجراحي\" (before an operation)\n",
    "    r\"\\bبعد\\sالتدخل\\sالجراحي\\b\",     # \"بعد التدخل الجراحي\" (after an operation)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (Assuming CSV)\n",
    "df = pd.read_excel(\"Train.xlsx\")\n",
    "\n",
    "# Specify the column containing extracted prescription text\n",
    "target_column = \"Prescription\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0                                                                                Carbachol Every 8 hours\n",
       "1         Ofloxacin كل ست  ساعات , Brimonidine كل ٦ ساعات , كارباشول عند اللزوم , Latanoprost مرة يومياً\n",
       "2                                                                           Brimonidine Before breakfast\n",
       "3          Carbachol عند اللزوم , Tobramycin عند اللزوم , Pilocarpine كل ٦ ساعات , لاتانوبروست قبل النوم\n",
       "4                                                      Fluorometholone As needed , Latanoprost As needed\n",
       "                                                     ...                                                \n",
       "618    Doxycycline مرة يومياً , كليندامايسين قبل النوم , موبيروسين مرتين يومياً , كلورهيكسيدين قبل النوم\n",
       "619                                                                              ديكلوفيناك مرتين يومياً\n",
       "620                                                                                  Nystatin بعد الغداء\n",
       "621                       Azithromycin قبل الفطار , سيبروفلوكساسين عند اللزوم , Metronidazole مرة يومياً\n",
       "622                      Mupirocin Once daily , Hydrocortisone Twice daily , Ciprofloxacin Every 6 hours\n",
       "Name: Prescription, Length: 623, dtype: object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[target_column].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_medicine_and_frequency(text):\n",
    "    \"\"\"\n",
    "    Extracts medicine names and dosage frequency while maintaining the original order.\n",
    "    Returns a list of dictionaries [{medicine: \"name\", frequency: \"value\"}].\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):  # Ensure text is a string\n",
    "        return []\n",
    "    \n",
    "    structured_output = []\n",
    "    \n",
    "    # Combine medicine names and frequency patterns into a single regex pattern\n",
    "    combined_pattern = r\"|\".join(\n",
    "        [re.escape(med) for med in medicine_list] + frequency_patterns\n",
    "    )\n",
    "\n",
    "    # Find all matches in the order they appear in the text\n",
    "    matches = re.findall(combined_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    current_medicine = None  # Track last detected medicine\n",
    "    \n",
    "    for match in matches:\n",
    "        if match in medicine_list:  \n",
    "            current_medicine = match  # Update the latest detected medicine\n",
    "            structured_output.append({\"medicine\": match, \"frequency\": \"\"})  # Default frequency\n",
    "        \n",
    "        elif current_medicine:  \n",
    "            # Assign the frequency to the last detected medicine **only if it does not have one yet**\n",
    "            if structured_output[-1][\"frequency\"] == \"\":\n",
    "                structured_output[-1][\"frequency\"] = match  \n",
    "            else:\n",
    "                # If previous medicine already has a frequency, store this frequency separately\n",
    "                structured_output.append({\"medicine\": current_medicine, \"frequency\": match})\n",
    "    \n",
    "    return structured_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                             [{'medicine': 'Carbachol', 'frequency': 'Every 8 hours'}]\n",
       "1                [{'medicine': 'Ofloxacin', 'frequency': ''}, {'medicine': 'Brimonidine', 'frequency': ''}, {'medicine': 'كارباشول', 'frequency': 'عند اللزوم'}, {'medicine': 'Latanoprost', 'frequency': 'مرة يوميا'}]\n",
       "2                                                                                                                                                        [{'medicine': 'Brimonidine', 'frequency': 'Before breakfast'}]\n",
       "3    [{'medicine': 'Carbachol', 'frequency': 'عند اللزوم'}, {'medicine': 'Tobramycin', 'frequency': 'عند اللزوم'}, {'medicine': 'Pilocarpine', 'frequency': ''}, {'medicine': 'لاتانوبروست', 'frequency': 'قبل النوم'}]\n",
       "4                                                                                                    [{'medicine': 'Fluorometholone', 'frequency': 'As needed'}, {'medicine': 'Latanoprost', 'frequency': 'As needed'}]\n",
       "Name: structured_prescriptions, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply extraction function to dataset\n",
    "df[\"structured_prescriptions\"] = df[target_column].apply(extract_medicine_and_frequency)\n",
    "\n",
    "# Convert the entire dataset into a list of lists of dictionaries\n",
    "structured_output = df[\"structured_prescriptions\"].tolist()\n",
    "\n",
    "# Print the final structured output\n",
    "df[\"structured_prescriptions\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_medicine_and_frequency(text):\n",
    "    if not isinstance(text, str):  # Ensure text is a string\n",
    "        return []\n",
    "    \n",
    "    structured_output = []\n",
    "    \n",
    "    # Combine medicine names and frequency patterns into a single regex pattern\n",
    "    combined_pattern = r\"|\".join(\n",
    "        [re.escape(med) for med in medicine_list] + frequency_patterns\n",
    "    )\n",
    "\n",
    "    # Find all matches in the order they appear in the text\n",
    "    matches = re.findall(combined_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    current_medicine = None  # Track last detected medicine\n",
    "    \n",
    "    for match in matches:\n",
    "        if match in medicine_list:  \n",
    "            current_medicine = match  # Update the latest detected medicine\n",
    "            structured_output.append({\"medicine\": match, \"frequency\": \"\"})  # Default frequency\n",
    "        \n",
    "        elif current_medicine:\n",
    "            # Assign the frequency to the last detected medicine **only if it does not have one yet**\n",
    "            if structured_output[-1][\"frequency\"] == \"\":\n",
    "                structured_output[-1][\"frequency\"] = match  \n",
    "            else:\n",
    "                # If previous medicine already has a frequency, store this frequency separately\n",
    "                structured_output.append({\"medicine\": current_medicine, \"frequency\": match})\n",
    "    \n",
    "    return structured_output\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    # Normalize the text to decompose characters into base characters and diacritics\n",
    "    normalized_text = unicodedata.normalize('NFKD', text)\n",
    "    \n",
    "    # Filter out combining characters (diacritics)\n",
    "    cleaned_text = ''.join(\n",
    "        char for char in normalized_text\n",
    "        if not unicodedata.combining(char)\n",
    "    )\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'medicine': 'Ofloxacin', 'frequency': 'كل ست ساعات'},\n",
       " {'medicine': 'Brimonidine', 'frequency': ''},\n",
       " {'medicine': 'كارباشول', 'frequency': 'عند اللزوم'},\n",
       " {'medicine': 'Latanoprost', 'frequency': 'مرة يوميا'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Ofloxacin كل ست ساعات , Brimonidine كل ٦ ساعات , كارباشول عند اللزوم , Latanoprost مرة يومياً\"\n",
    "# text = \"Carbachol عند اللزوم , Tobramycin عند اللزوم , Pilocarpine كل ٦ ساعات , لاتانوبروست قبل النوم\"\n",
    "# text = \"Doxycycline مرة يومياً , كليندامايسين قبل النوم , موبيروسين مرتين يومياً , كلورهيكسيدين قبل النوم\"\n",
    "\n",
    "text = remove_diacritics(text)\n",
    "result = extract_medicine_and_frequency(text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_FREQUENCY = \"Every 6 hours\"\n",
    "\n",
    "def extract_medicine_and_frequency(sentence, medicine_list, frequency_patterns):\n",
    "    extracted_medicines = []\n",
    "    extracted_frequencies = []\n",
    "    medicine_positions = {}\n",
    "    frequency_positions = {}\n",
    "\n",
    "    # Step 1: Extract medicines and their positions\n",
    "    for med in medicine_list:\n",
    "        match = re.search(rf\"\\b{re.escape(med)}\\b\", sentence)\n",
    "        if match:\n",
    "            extracted_medicines.append(med)\n",
    "            medicine_positions[med] = match.start()\n",
    "\n",
    "    # Step 2: Extract frequencies and their positions\n",
    "    for pattern in frequency_patterns:\n",
    "        pattern_re = re.compile(pattern)\n",
    "        matches = pattern_re.finditer(sentence)\n",
    "        for match in matches:\n",
    "            extracted_frequencies.append(match.group())\n",
    "            frequency_positions[match.group()] = match.start()\n",
    "\n",
    "    # Step 3: Sort medicines and frequencies by their position\n",
    "    sorted_medicines = sorted(medicine_positions.items(), key=lambda x: x[1])\n",
    "    sorted_frequencies = sorted(frequency_positions.items(), key=lambda x: x[1])\n",
    "\n",
    "    # Step 4: Pair medicines with frequencies\n",
    "    extracted_results = []\n",
    "    freq_index = 0\n",
    "    last_known_frequency = None\n",
    "    \n",
    "    for i, (med, med_pos) in enumerate(sorted_medicines):\n",
    "        extracted_frequency = \"Unknown\"\n",
    "        next_med_pos = sorted_medicines[i + 1][1] if i + 1 < len(sorted_medicines) else len(sentence)\n",
    "\n",
    "        # Check if there are words between this medicine and the next\n",
    "        words_between = sentence[med_pos + len(med):next_med_pos].strip()\n",
    "        if words_between and len(words_between.split()) <= 3:\n",
    "            extracted_frequency = words_between\n",
    "        else:\n",
    "            # Try to match frequency after the medicine (if ordered correctly)\n",
    "            while freq_index < len(sorted_frequencies):\n",
    "                freq, freq_pos = sorted_frequencies[freq_index]\n",
    "                if freq_pos > med_pos and freq_pos < next_med_pos:\n",
    "                    extracted_frequency = freq\n",
    "                    last_known_frequency = freq\n",
    "                    freq_index += 1\n",
    "                    break\n",
    "                freq_index += 1\n",
    "\n",
    "            # If no direct match, use last known frequency\n",
    "            if extracted_frequency == \"Unknown\" and last_known_frequency:\n",
    "                extracted_frequency = last_known_frequency\n",
    "\n",
    "            # If still unknown, use default\n",
    "            if extracted_frequency == \"Unknown\":\n",
    "                extracted_frequency = DEFAULT_FREQUENCY\n",
    "\n",
    "        extracted_results.append((med, extracted_frequency))\n",
    "    \n",
    "    return extracted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paracetamol hours Every Oral Amoxicillin other lunch After Erythromycin Nystatin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Paracetamol', 'hours Every'),\n",
       " ('Oral Amoxicillin', 'Every 6 hours'),\n",
       " ('Amoxicillin', 'other lunch After'),\n",
       " ('Erythromycin', 'Every 6 hours'),\n",
       " ('Nystatin', 'Every 6 hours')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = \"Doxycycline مرة يومياً , كليندامايسين قبل النوم , موبيروسين مرتين يومياً , كلورهيكسيدين قبل النوم\"\n",
    "text = \"Paracetamol hours Every Oral Amoxicillin other lunch After Erythromycin Nystatin\"\n",
    "\n",
    "print(text)\n",
    "text = remove_diacritics(text)\n",
    "result = extract_medicine_and_frequency(text, medicine_list, frequency_patterns)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try with bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prescriptions using regex-based extraction...\n",
      "\n",
      "Prescription 1:\n",
      "Text: Carbachol Every 8 hours\n",
      "Medication Schedule:\n",
      "  - Medication: Carbachol, Frequency: Every 8 hours (Confidence: 0.99)\n",
      "\n",
      "Prescription 2:\n",
      "Text: Ofloxacin كل ست ساعات, Brimonidine كل ٦ ساعات, كارباشول عند اللزوم, Latanoprost مرة يومياً\n",
      "Medication Schedule:\n",
      "  - Medication: Ofloxacin, Frequency: every 6 hours (Confidence: 0.99)\n",
      "  - Medication: Brimonidine, Frequency: every 6 hours (Confidence: 0.99)\n",
      "  - Medication: Carbachol, Frequency: as needed (Confidence: 0.99)\n",
      "  - Medication: Latanoprost, Frequency: once daily (Confidence: 0.99)\n",
      "\n",
      "Prescription 3:\n",
      "Text: Brimonidine Before breakfast\n",
      "Medication Schedule:\n",
      "  - Medication: Brimonidine, Frequency: Before breakfast (Confidence: 0.99)\n",
      "\n",
      "Prescription 4:\n",
      "Text: Carbachol عند اللزوم, Tobramycin عند اللزوم, Pilocarpine كل ٦ ساعات, لاتانوبروست قبل النوم\n",
      "Medication Schedule:\n",
      "  - Medication: Carbachol, Frequency: as needed (Confidence: 0.99)\n",
      "  - Medication: Tobramycin, Frequency: as needed (Confidence: 0.99)\n",
      "  - Medication: Pilocarpine, Frequency: every 6 hours (Confidence: 0.99)\n",
      "  - Medication: Latanoprost, Frequency: before sleep (Confidence: 0.99)\n",
      "\n",
      "Prescription 5:\n",
      "Text: Fluorometholone As needed, Latanoprost As needed\n",
      "Medication Schedule:\n",
      "  - Medication: Fluorometholone, Frequency: As needed (Confidence: 0.99)\n",
      "  - Medication: Latanoprost, Frequency: As needed (Confidence: 0.99)\n",
      "\n",
      "Prescription 6:\n",
      "Text: Brimonidine قبل النوم, Dorzolamide بعد الغداء\n",
      "Medication Schedule:\n",
      "  - Medication: Brimonidine, Frequency: before sleep (Confidence: 0.99)\n",
      "  - Medication: Dorzolamide, Frequency: after lunch (Confidence: 0.99)\n",
      "\n",
      "Prescription 7:\n",
      "Text: دورزولاميد قبل النوم, تيمولول عند اللزوم, قطرات بريدنيزولون كل ٨ ساعات, أوفلوكساسين كل ٦ ساعات\n",
      "Medication Schedule:\n",
      "  - Medication: Dorzolamide, Frequency: before sleep (Confidence: 0.99)\n",
      "  - Medication: Timolol, Frequency: as needed (Confidence: 0.99)\n",
      "  - Medication: Prednisolone, Frequency: every 8 hours (Confidence: 0.99)\n",
      "  - Medication: Ofloxacin, Frequency: every 6 hours (Confidence: 0.99)\n",
      "\n",
      "Prescription 8:\n",
      "Text: لاتانوبروست قبل النوم, توبراميسين مرة يومياً, كارباشول كل ٦ ساعات\n",
      "Medication Schedule:\n",
      "  - Medication: Latanoprost, Frequency: before sleep (Confidence: 0.99)\n",
      "  - Medication: Tobramycin, Frequency: once daily (Confidence: 0.99)\n",
      "  - Medication: Carbachol, Frequency: every 6 hours (Confidence: 0.99)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from datasets import Dataset\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.util import filter_spans\n",
    "import numpy as np\n",
    "\n",
    "class MedicalPrescriptionNER:\n",
    "    def __init__(self, model_name=\"distilbert-base-multilingual-cased\"):\n",
    "        \"\"\"\n",
    "        Initialize the NER system for medical prescriptions\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.ner_pipeline = None\n",
    "        \n",
    "        # For custom training\n",
    "        self.labels = [\"O\", \"B-MEDICATION\", \"I-MEDICATION\", \"B-FREQUENCY\", \"I-FREQUENCY\"]\n",
    "        self.id2label = {i: label for i, label in enumerate(self.labels)}\n",
    "        self.label2id = {label: i for i, label in enumerate(self.labels)}\n",
    "        \n",
    "        # Arabic frequency phrases and their standardized mappings\n",
    "        self.arabic_frequencies = {\n",
    "            \"كل ست ساعات\": \"every 6 hours\",\n",
    "            \"كل ٦ ساعات\": \"every 6 hours\",\n",
    "            \"عند اللزوم\": \"as needed\",\n",
    "            \"مرة يومياً\": \"once daily\",\n",
    "            \"قبل النوم\": \"before sleep\",\n",
    "            \"قبل الإفطار\": \"before breakfast\",\n",
    "            \"بعد الغداء\": \"after lunch\",\n",
    "            \"كل ٨ ساعات\": \"every 8 hours\"\n",
    "        }\n",
    "        \n",
    "        # English medication names and their Arabic transliterations\n",
    "        self.medication_mappings = {\n",
    "            \"كارباشول\": \"Carbachol\",\n",
    "            \"أوفلوكساسين\": \"Ofloxacin\",\n",
    "            \"لاتانوبروست\": \"Latanoprost\",\n",
    "            \"بريمونيدين\": \"Brimonidine\",\n",
    "            \"توبراميسين\": \"Tobramycin\",\n",
    "            \"بيلوكاربين\": \"Pilocarpine\",\n",
    "            \"فلوروميثولون\": \"Fluorometholone\",\n",
    "            \"دورزولاميد\": \"Dorzolamide\",\n",
    "            \"تيمولول\": \"Timolol\",\n",
    "            \"بريدنيزولون\": \"Prednisolone\"\n",
    "        }\n",
    "        \n",
    "        # Initialize pattern matchers\n",
    "        self._initialize_patterns()\n",
    "    \n",
    "    def _initialize_patterns(self):\n",
    "        \"\"\"Initialize regex patterns for medications and frequencies\"\"\"\n",
    "        # Common medication patterns\n",
    "        common_medications = [\n",
    "            \"Carbachol\", \"Ofloxacin\", \"Brimonidine\", \"Latanoprost\", \"Tobramycin\",\n",
    "            \"Pilocarpine\", \"Fluorometholone\", \"Dorzolamide\", \"Timolol\", \"Prednisolone\"\n",
    "        ]\n",
    "        \n",
    "        # Build pattern for medication names (case insensitive)\n",
    "        self.medication_pattern = re.compile(\n",
    "            r'\\b(' + '|'.join(common_medications) + r')\\b', \n",
    "            re.IGNORECASE\n",
    "        )\n",
    "        \n",
    "        # Common frequency patterns in English\n",
    "        self.eng_frequency_pattern = re.compile(\n",
    "            r'\\b(every\\s+\\d+\\s+hours?|'\n",
    "            r'once daily|twice daily|'\n",
    "            r'before (breakfast|lunch|dinner|sleep|bed)|'\n",
    "            r'after (breakfast|lunch|dinner)|'\n",
    "            r'as needed|daily|weekly|monthly|'\n",
    "            r'\\d+ times? (daily|a day))\\b',\n",
    "            re.IGNORECASE\n",
    "        )\n",
    "        \n",
    "        # Arabic frequency patterns (needs simplified regex for demo)\n",
    "        self.arabic_frequency_pattern = re.compile(\n",
    "            '|'.join(map(re.escape, self.arabic_frequencies.keys()))\n",
    "        )\n",
    "    \n",
    "    def load_pretrained_model(self):\n",
    "        \"\"\"Load a pretrained multilingual NER model\"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(\n",
    "            self.model_name, \n",
    "            num_labels=len(self.labels),\n",
    "            id2label=self.id2label,\n",
    "            label2id=self.label2id\n",
    "        )\n",
    "        self.ner_pipeline = pipeline(\n",
    "            \"ner\", \n",
    "            model=self.model, \n",
    "            tokenizer=self.tokenizer,\n",
    "            aggregation_strategy=\"simple\"  # Merge subwords\n",
    "        )\n",
    "        \n",
    "        print(f\"Loaded pretrained model: {self.model_name}\")\n",
    "        \n",
    "    def prepare_training_data(self, prescriptions):\n",
    "        \"\"\"\n",
    "        Prepare training data from prescription list using pattern matching\n",
    "        Returns data in format suitable for spaCy training\n",
    "        \"\"\"\n",
    "        training_data = []\n",
    "        \n",
    "        for text in prescriptions:\n",
    "            doc = {\"text\": text, \"entities\": []}\n",
    "            \n",
    "            # Find medications using regex\n",
    "            for med_match in self.medication_pattern.finditer(text):\n",
    "                doc[\"entities\"].append({\n",
    "                    \"start\": med_match.start(),\n",
    "                    \"end\": med_match.end(),\n",
    "                    \"label\": \"MEDICATION\"\n",
    "                })\n",
    "            \n",
    "            # Find Arabic medication names\n",
    "            for ar_med, en_med in self.medication_mappings.items():\n",
    "                for match in re.finditer(re.escape(ar_med), text):\n",
    "                    doc[\"entities\"].append({\n",
    "                        \"start\": match.start(),\n",
    "                        \"end\": match.end(),\n",
    "                        \"label\": \"MEDICATION\"\n",
    "                    })\n",
    "            \n",
    "            # Find English frequencies\n",
    "            for freq_match in self.eng_frequency_pattern.finditer(text):\n",
    "                doc[\"entities\"].append({\n",
    "                    \"start\": freq_match.start(),\n",
    "                    \"end\": freq_match.end(),\n",
    "                    \"label\": \"FREQUENCY\"\n",
    "                })\n",
    "            \n",
    "            # Find Arabic frequencies\n",
    "            for ar_freq_match in self.arabic_frequency_pattern.finditer(text):\n",
    "                doc[\"entities\"].append({\n",
    "                    \"start\": ar_freq_match.start(),\n",
    "                    \"end\": ar_freq_match.end(),\n",
    "                    \"label\": \"FREQUENCY\"\n",
    "                })\n",
    "            \n",
    "            training_data.append(doc)\n",
    "        \n",
    "        return training_data\n",
    "    \n",
    "    def prepare_spacy_data(self, training_data):\n",
    "        \"\"\"Convert training data to spaCy format\"\"\"\n",
    "        nlp = spacy.blank(\"xx\")  # multilingual blank model\n",
    "        db = DocBin()\n",
    "        \n",
    "        for example in training_data:\n",
    "            text = example[\"text\"]\n",
    "            doc = nlp.make_doc(text)\n",
    "            \n",
    "            # Sort entities by start position\n",
    "            entities = sorted(example[\"entities\"], key=lambda e: e[\"start\"])\n",
    "            \n",
    "            # Create span objects\n",
    "            spans = [doc.char_span(e[\"start\"], e[\"end\"], label=e[\"label\"]) \n",
    "                     for e in entities]\n",
    "            spans = [span for span in spans if span is not None]\n",
    "            \n",
    "            # Filter overlapping spans\n",
    "            filtered_spans = filter_spans(spans)\n",
    "            \n",
    "            # Add spans to document\n",
    "            doc.spans[\"entities\"] = filtered_spans\n",
    "            db.add(doc)\n",
    "        \n",
    "        return db\n",
    "    \n",
    "    def train_spacy_model(self, training_data, output_dir=\"./med_ner_model\"):\n",
    "        \"\"\"Train a spaCy model with the prepared data\"\"\"\n",
    "        db = self.prepare_spacy_data(training_data)\n",
    "        \n",
    "        # Save converted training data\n",
    "        db.to_disk(\"./train_data.spacy\")\n",
    "        \n",
    "        # Command to run in shell (not executed here):\n",
    "        print(\"Run the following command to train the model:\")\n",
    "        print(f\"python -m spacy train config.cfg --output {output_dir} --paths.train train_data.spacy --paths.dev train_data.spacy\")\n",
    "    \n",
    "    def train_transformer_model(self, training_data, output_dir=\"./med_ner_transformer\"):\n",
    "        \"\"\"Train a transformer model with the prepared data\"\"\"\n",
    "        # Convert to IOB format for transformer training\n",
    "        tokenized_inputs = []\n",
    "        tags = []\n",
    "        \n",
    "        for example in training_data:\n",
    "            text = example[\"text\"]\n",
    "            tokens = []\n",
    "            labels = [\"O\"] * len(text.split())  # Initialize all as Outside\n",
    "            \n",
    "            # Process each character position\n",
    "            for i, char in enumerate(text):\n",
    "                # Check if this position starts an entity\n",
    "                for entity in example[\"entities\"]:\n",
    "                    if i == entity[\"start\"]:\n",
    "                        entity_tokens = text[entity[\"start\"]:entity[\"end\"]].split()\n",
    "                        entity_idx = len(tokens)\n",
    "                        for j, token in enumerate(entity_tokens):\n",
    "                            if j == 0:\n",
    "                                labels[entity_idx + j] = f\"B-{entity['label']}\"\n",
    "                            else:\n",
    "                                labels[entity_idx + j] = f\"I-{entity['label']}\"\n",
    "                \n",
    "                # Add token if it's a word boundary\n",
    "                if char.isspace() or i == 0:\n",
    "                    if i > 0 and text[i-1].isspace():\n",
    "                        continue\n",
    "                    word = \"\"\n",
    "                    j = i\n",
    "                    while j < len(text) and not text[j].isspace():\n",
    "                        word += text[j]\n",
    "                        j += 1\n",
    "                    if word:\n",
    "                        tokens.append(word)\n",
    "            \n",
    "            tokenized_inputs.append(tokens)\n",
    "            tags.append(labels[:len(tokens)])  # Ensure labels match tokens\n",
    "        \n",
    "        # Convert to HuggingFace dataset format\n",
    "        dataset_dict = {\n",
    "            \"tokens\": tokenized_inputs,\n",
    "            \"ner_tags\": tags\n",
    "        }\n",
    "        dataset = Dataset.from_dict(dataset_dict)\n",
    "        \n",
    "        # Print training info\n",
    "        print(f\"Created training dataset with {len(dataset)} examples\")\n",
    "        print(\"Sample tokens:\", dataset[0][\"tokens\"])\n",
    "        print(\"Sample tags:\", dataset[0][\"ner_tags\"])\n",
    "        \n",
    "        # Code to train the transformer model (not executed here)\n",
    "        print(\"\\nTo train the transformer model, use HuggingFace Trainer...\")\n",
    "    \n",
    "    def extract_entities_with_regex(self, text):\n",
    "        \"\"\"Extract medications and frequencies using regex patterns\"\"\"\n",
    "        entities = []\n",
    "        \n",
    "        # Extract English medications\n",
    "        for match in self.medication_pattern.finditer(text):\n",
    "            entities.append({\n",
    "                \"entity\": \"MEDICATION\",\n",
    "                \"value\": match.group(),\n",
    "                \"start\": match.start(),\n",
    "                \"end\": match.end()\n",
    "            })\n",
    "        \n",
    "        # Extract Arabic medications\n",
    "        for ar_med, en_med in self.medication_mappings.items():\n",
    "            for match in re.finditer(re.escape(ar_med), text):\n",
    "                entities.append({\n",
    "                    \"entity\": \"MEDICATION\",\n",
    "                    \"value\": ar_med,\n",
    "                    \"normalized\": en_med,\n",
    "                    \"start\": match.start(),\n",
    "                    \"end\": match.end()\n",
    "                })\n",
    "        \n",
    "        # Extract English frequencies\n",
    "        for match in self.eng_frequency_pattern.finditer(text):\n",
    "            entities.append({\n",
    "                \"entity\": \"FREQUENCY\",\n",
    "                \"value\": match.group(),\n",
    "                \"start\": match.start(),\n",
    "                \"end\": match.end()\n",
    "            })\n",
    "        \n",
    "        # Extract Arabic frequencies\n",
    "        for match in self.arabic_frequency_pattern.finditer(text):\n",
    "            ar_freq = match.group()\n",
    "            entities.append({\n",
    "                \"entity\": \"FREQUENCY\",\n",
    "                \"value\": ar_freq,\n",
    "                \"normalized\": self.arabic_frequencies.get(ar_freq, ar_freq),\n",
    "                \"start\": match.start(),\n",
    "                \"end\": match.end()\n",
    "            })\n",
    "        \n",
    "        # Sort by position in text\n",
    "        entities.sort(key=lambda x: x[\"start\"])\n",
    "        \n",
    "        return entities\n",
    "    \n",
    "    def pair_medications_with_frequencies(self, entities, text):\n",
    "        \"\"\"Pair medications with their frequencies based on proximity\"\"\"\n",
    "        medications = [e for e in entities if e[\"entity\"] == \"MEDICATION\"]\n",
    "        frequencies = [e for e in entities if e[\"entity\"] == \"FREQUENCY\"]\n",
    "        \n",
    "        pairs = []\n",
    "        \n",
    "        for med in medications:\n",
    "            # Find closest frequency\n",
    "            closest_freq = None\n",
    "            min_distance = float('inf')\n",
    "            \n",
    "            for freq in frequencies:\n",
    "                # Check if frequency follows medication\n",
    "                if freq[\"start\"] > med[\"end\"]:\n",
    "                    # Distance to next frequency\n",
    "                    distance = freq[\"start\"] - med[\"end\"]\n",
    "                    \n",
    "                    # Check if there's another medication between this med and freq\n",
    "                    has_med_between = any(\n",
    "                        m[\"start\"] > med[\"end\"] and m[\"end\"] < freq[\"start\"] \n",
    "                        for m in medications if m != med\n",
    "                    )\n",
    "                    \n",
    "                    if not has_med_between and distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        closest_freq = freq\n",
    "                        \n",
    "                        # If they're adjacent with only comma/whitespace, this is a strong match\n",
    "                        sep_text = text[med[\"end\"]:freq[\"start\"]]\n",
    "                        if re.match(r'^[\\s,]*$', sep_text):\n",
    "                            break\n",
    "            \n",
    "            # If no frequency found after, look for one before (less common but possible)\n",
    "            if closest_freq is None:\n",
    "                for freq in frequencies:\n",
    "                    if freq[\"end\"] < med[\"start\"]:\n",
    "                        distance = med[\"start\"] - freq[\"end\"]\n",
    "                        \n",
    "                        has_med_between = any(\n",
    "                            m[\"end\"] > freq[\"end\"] and m[\"start\"] < med[\"start\"] \n",
    "                            for m in medications if m != med\n",
    "                        )\n",
    "                        \n",
    "                        if not has_med_between and distance < min_distance:\n",
    "                            min_distance = distance\n",
    "                            closest_freq = freq\n",
    "            \n",
    "            # Only pair if the frequency is reasonably close\n",
    "            if closest_freq and min_distance < 50:  # Arbitrary threshold\n",
    "                pairs.append({\n",
    "                    \"medication\": med.get(\"normalized\", med[\"value\"]),\n",
    "                    \"frequency\": closest_freq.get(\"normalized\", closest_freq[\"value\"]),\n",
    "                    \"confidence\": 1.0 - (min_distance / 100)  # Higher confidence for closer pairs\n",
    "                })\n",
    "            else:\n",
    "                # Medication without clear frequency\n",
    "                pairs.append({\n",
    "                    \"medication\": med.get(\"normalized\", med[\"value\"]),\n",
    "                    \"frequency\": \"unspecified\",\n",
    "                    \"confidence\": 0.5\n",
    "                })\n",
    "        \n",
    "        return pairs\n",
    "    \n",
    "    def process_prescription(self, text):\n",
    "        \"\"\"Process a single prescription text\"\"\"\n",
    "        # Extract entities using regex (faster for prototype)\n",
    "        entities = self.extract_entities_with_regex(text)\n",
    "        \n",
    "        # Pair medications with frequencies\n",
    "        medication_frequency_pairs = self.pair_medications_with_frequencies(entities, text)\n",
    "        \n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"entities\": entities,\n",
    "            \"medication_schedule\": medication_frequency_pairs\n",
    "        }\n",
    "    \n",
    "    def batch_process(self, prescription_list):\n",
    "        \"\"\"Process a batch of prescriptions\"\"\"\n",
    "        results = []\n",
    "        for text in prescription_list:\n",
    "            results.append(self.process_prescription(text))\n",
    "        return results\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Example prescription data\n",
    "    prescriptions = [\n",
    "        \"Carbachol Every 8 hours\",\n",
    "        \"Ofloxacin كل ست ساعات, Brimonidine كل ٦ ساعات, كارباشول عند اللزوم, Latanoprost مرة يومياً\",\n",
    "        \"Brimonidine Before breakfast\",\n",
    "        \"Carbachol عند اللزوم, Tobramycin عند اللزوم, Pilocarpine كل ٦ ساعات, لاتانوبروست قبل النوم\",\n",
    "        \"Fluorometholone As needed, Latanoprost As needed\",\n",
    "        \"Brimonidine قبل النوم, Dorzolamide بعد الغداء\",\n",
    "        \"دورزولاميد قبل النوم, تيمولول عند اللزوم, قطرات بريدنيزولون كل ٨ ساعات, أوفلوكساسين كل ٦ ساعات\",\n",
    "        \"لاتانوبروست قبل النوم, توبراميسين مرة يومياً, كارباشول كل ٦ ساعات\"\n",
    "    ]\n",
    "\n",
    "    # Initialize the NER system\n",
    "    ner_system = MedicalPrescriptionNER()\n",
    "\n",
    "    # Option 1: Use regex-based extraction (faster for prototyping)\n",
    "    print(\"Processing prescriptions using regex-based extraction...\")\n",
    "    results = ner_system.batch_process(prescriptions)\n",
    "\n",
    "    # Display results\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"\\nPrescription {i + 1}:\")\n",
    "        print(f\"Text: {result['text']}\")\n",
    "        print(\"Medication Schedule:\")\n",
    "        for pair in result[\"medication_schedule\"]:\n",
    "            print(f\"  - Medication: {pair['medication']}, Frequency: {pair['frequency']} (Confidence: {pair['confidence']:.2f})\")\n",
    "\n",
    "    # Option 2: Load a pre-trained model (if available)\n",
    "    # Uncomment the following lines to use a pre-trained model instead of regex:\n",
    "    # print(\"\\nLoading pre-trained model...\")\n",
    "    # ner_system.load_pretrained_model()\n",
    "    # results = ner_system.batch_process(prescriptions)\n",
    "\n",
    "    # Option 3: Train a custom model (if labeled data is available)\n",
    "    # Uncomment the following lines to prepare training data and train a model:\n",
    "    # print(\"\\nPreparing training data...\")\n",
    "    # training_data = ner_system.prepare_training_data(prescriptions)\n",
    "    # print(\"\\nTraining spaCy model...\")\n",
    "    # ner_system.train_spacy_model(training_data)\n",
    "    # print(\"\\nTraining transformer model...\")\n",
    "    # ner_system.train_transformer_model(training_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try with NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import spacy\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# Define the NER system class\n",
    "class MedicalPrescriptionNER:\n",
    "    def __init__(self):\n",
    "        self.medication_list = [\"Carbachol\", \"Ofloxacin\", \"Brimonidine\", \"Latanoprost\", \"Pilocarpine\", \"Tobramycin\", \"Fluorometholone\", \"Dorzolamide\", \"Timolol\", \"Prednisolone\"]\n",
    "        self.frequency_patterns = [\n",
    "            (r'كل\\s*(\\d+)\\s*ساعات', 'every \\1 hours'),\n",
    "            (r'قبل النوم', 'before bed'),\n",
    "            (r'بعد الغداء', 'after lunch'),\n",
    "            (r'مرة يومياً', 'once daily'),\n",
    "            (r'عند اللزوم', 'as needed'),\n",
    "            (r'Every (\\d+) hours', 'every \\1 hours'),\n",
    "            (r'Before breakfast', 'before breakfast'),\n",
    "            (r'As needed', 'as needed')\n",
    "        ]\n",
    "    \n",
    "    def extract_entities(self, text):\n",
    "        entities = []\n",
    "        for med in self.medication_list:\n",
    "            if med in text:\n",
    "                entities.append((med, 'MEDICATION'))\n",
    "        for pattern, freq in self.frequency_patterns:\n",
    "            matches = re.findall(pattern, text)\n",
    "            if matches:\n",
    "                for match in matches:\n",
    "                    extracted_freq = freq.replace('\\\\1', match) if '\\\\1' in freq else freq\n",
    "                    entities.append((extracted_freq, 'FREQUENCY'))\n",
    "        return entities\n",
    "    \n",
    "    def batch_process(self, prescriptions):\n",
    "        processed_data = []\n",
    "        for text in prescriptions:\n",
    "            entities = self.extract_entities(text)\n",
    "            processed_data.append({\"text\": text, \"entities\": entities})\n",
    "        return processed_data\n",
    "\n",
    "def prepare_training_data(processed_data):\n",
    "    labeled_data = []\n",
    "    for entry in processed_data:\n",
    "        text = entry['text']\n",
    "        labels = ['O'] * len(text)\n",
    "        for entity, label in entry['entities']:\n",
    "            start_idx = text.find(entity)\n",
    "            if start_idx != -1:\n",
    "                for i in range(start_idx, start_idx + len(entity)):\n",
    "                    labels[i] = 'B-' + label if i == start_idx else 'I-' + label\n",
    "        labeled_data.append({\"tokens\": list(text), \"labels\": labels})\n",
    "    return labeled_data\n",
    "\n",
    "def train_ner_model(training_data):\n",
    "    model_name = \"distilbert-base-multilingual-cased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=3)\n",
    "    \n",
    "    tokenized_inputs = tokenizer([d['tokens'] for d in training_data], truncation=True, padding=True, is_split_into_words=True)\n",
    "    labels = [[0 if l == 'O' else 1 for l in d['labels']] for d in training_data]\n",
    "    \n",
    "    dataset = [{\"input_ids\": tokenized_inputs['input_ids'][i], \"attention_mask\": tokenized_inputs['attention_mask'][i], \"labels\": labels[i]} for i in range(len(labels))]\n",
    "    \n",
    "    training_args = TrainingArguments(output_dir=\"./ner_model\", num_train_epochs=3, per_device_train_batch_size=4)\n",
    "    trainer = Trainer(model=model, args=training_args, train_dataset=dataset)\n",
    "    trainer.train()\n",
    "    model.save_pretrained(\"./ner_model\")\n",
    "\n",
    "def main():\n",
    "    prescriptions = [\n",
    "        \"Carbachol Every 8 hours\",\n",
    "        \"Ofloxacin كل ست ساعات, Brimonidine كل ٦ ساعات, كارباشول عند اللزوم, Latanoprost مرة يومياً\",\n",
    "        \"Brimonidine Before breakfast\",\n",
    "        \"Carbachol عند اللزوم, Tobramycin عند اللزوم, Pilocarpine كل ٦ ساعات, لاتانوبروست قبل النوم\",\n",
    "        \"Fluorometholone As needed, Latanoprost As needed\",\n",
    "        \"Brimonidine قبل النوم, Dorzolamide بعد الغداء\",\n",
    "        \"دورزولاميد قبل النوم, تيمولول عند اللزوم, قطرات بريدنيزولون كل ٨ ساعات, أوفلوكساسين كل ٦ ساعات\",\n",
    "        \"لاتانوبروست قبل النوم, توبراميسين مرة يومياً, كارباشول كل ٦ ساعات\"\n",
    "    ]\n",
    "\n",
    "    ner_system = MedicalPrescriptionNER()\n",
    "    results = ner_system.batch_process(prescriptions)\n",
    "    training_data = prepare_training_data(results)\n",
    "    \n",
    "    with open(\"training_data.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(training_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(\"Training data saved! Starting model training...\")\n",
    "    train_ner_model(training_data)\n",
    "    print(\"Model training completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "model_name = \"med_ner_model\"  # Change this to your actual model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Initialize a NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_medications(text):\n",
    "    ner_results = ner_pipeline(text)\n",
    "    \n",
    "    extracted_entities = []\n",
    "    current_entity = {\"word\": \"\", \"entity\": \"\"}\n",
    "    \n",
    "    for entity in ner_results:\n",
    "        word = entity[\"word\"].replace(\"▁\", \"\")  # Handling subword tokenization artifacts\n",
    "        if entity[\"entity\"].startswith(\"B-\"):  # Beginning of a new entity\n",
    "            if current_entity[\"word\"]:  # Save the previous entity\n",
    "                extracted_entities.append(current_entity)\n",
    "            current_entity = {\"word\": word, \"entity\": entity[\"entity\"][2:]}\n",
    "        elif entity[\"entity\"].startswith(\"I-\") and current_entity[\"entity\"]:  # Inside the same entity\n",
    "            current_entity[\"word\"] += \" \" + word\n",
    "    \n",
    "    # Add the last entity\n",
    "    if current_entity[\"word\"]:\n",
    "        extracted_entities.append(current_entity)\n",
    "\n",
    "    return extracted_entities\n",
    "\n",
    "# Example prediction\n",
    "prescription_text = \"Brimonidine كل ٦ ساعات, Carbachol عند اللزوم, Latanoprost مرة يومياً\"\n",
    "predictions = predict_medications(prescription_text)\n",
    "\n",
    "# Display results\n",
    "for entity in predictions:\n",
    "    print(f\"Extracted: {entity['word']} - Label: {entity['entity']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
